% This is Chapter 3
% !TEX root = ../main.tex
% #############################################################################
\fancychapter{The Method of Fundamental Solutions}
% \cleardoublepage
\label{chap:numerical}
% #############################################################################

\section{Density and linear independence results}\label{density_proofs_section}

The Method of Fundamental Solutions is the base method to be implemented throughout this work. As a meshless method, it does not involve any kind of domain discretization (into some mesh) like in finite differences or finite elements methods. Instead, one faces a point placement problem. Considering that mesh generation constitutes a computationally intensive aspect of the aforementioned methods, the \ac{MFS} stands out due to its distinct advantage of circumventing this necessity.
%This characteristic alleviates a major drawback inherent in other techniques, where the process of mesh generation significantly contributes to computational complexity.

As the name implies, the \ac{MFS} is based on the fundamental solution of a given elliptic \ac{PDE}. Consider the elliptic linear differential operator $\mathcal{L}$, with a fundamental solution $\Phi$ such that $\mathcal{L}\Phi(x) = \delta$ for all $x \in \mathbb{R}^d$. In essence, we utilize this fundamental solution to construct the approximation
\begin{equation}\label{chapt_numerical_mfs_approx_intro}
\Tilde{u}(x) = \sum_{j=1}^{N}\alpha_j \Phi(x-y_j),
\end{equation}
to the \ac{BVP}
\[
\begin{cases}
    \mathcal{L}u(x) = 0, & \text{for } x \in \Omega\\
    \mathcal{B}u(x) = 0, & \text{for } x \in \partial\Omega,
\end{cases}
\]
where $\mathcal{B}$ is a linear boundary operator.

In equation \eqref{chapt_numerical_mfs_approx_intro}, $y_j \in \mathbb{R}^d\setminus \overline{\Omega}$ for $j=1,\dots, N$ are the so-called source points, which we deliberately place outside the domain, since, under translation, the fundamental solutions exhibit singularities at each $y_j$. Otherwise, our approximation would introduce singularities within $\Omega$. By definition and using the linearity of the operator $\mathcal{L}$, $\tilde{u}$ satisfies the equation within $\Omega$, and we can determine the coefficients $\alpha_j$ by imposing the boundary conditions

\[
\mathcal{B}\tilde{u}(x) = \sum_{j=1}^{N}\alpha_j \mathcal{B}\Phi(x-y_j) = 0.
\]



\begin{remark}\label{chatp_numerical_remark_conv_motivation}
    While the motivation above might seem far-fetched, it's worth noting that the approximation $\Tilde{u}$ resembles a convolution between some density function $\alpha(x)$ and the fundamental solution $\Phi$. As we will see below, it can be proven that the fundamental solutions of the operator $\mathcal{L}$ are dense in the functional space defined on $\partial\Omega$ (which is sufficient since, as already discussed, the \ac{PDE} is satisfied by construction). For example, for Dirichlet boundary conditions, one sets $\mathcal{B} = I$ and utilizes the single layer potential
    \[
        u(x) = \int_{\hat{\Gamma}}\Phi(x-y)\varphi(y)d\sigma(y), \text{ for } x \in \mathbb{R}^2\setminus \hat{\Gamma},
    \]
    which is continuous in $\mathbb{R}^2$, where $\varphi(y)$ is a layer density to be determined and \(\hat{\Gamma}\) is some (source) set placed outside \(\Omega\) (in Definition \ref{source_set_definition} below we formalize this concept rigorously). Through a discretization approach, one can consider the approximation
    \begin{equation}\label{MFS_approx_disc}
    u(x) \approx \sum_{j=1}^{N}w_j \varphi(y_j) \Phi(x-y_j) = \Tilde{u}(x),
    \end{equation}
    where $y_j \in \hat{\Gamma}$ and $w_j$ are the nodes and weights of some quadrature, respectively. By setting $\alpha_j = w_j \varphi(y_j)$, we recover the earlier approximation.

\end{remark}
First, we introduce the notion of \textit{artificial boundary} (or \textit{pseudo-boundary}), which is analyzed in \cite{alves2009choice}.
\begin{definition}\label{source_set_definition}
    A source set \(\hat{\Gamma}\) is said to be admissible if
    \begin{enumerate}
        \item \(\hat{\Gamma} \subset \mathbb{R}^d\setminus \overline{\Omega}\) is an open set with components in each external part of \(\Omega\);
        \item \label{source_set_definition_2} \(\hat{\Gamma} = \partial \hat{\Omega}\) is the boundary of \(\hat{\Omega}\), where \(\hat{\Omega} \subset \mathbb{R}^d\setminus\overline{\Omega}\) is an open set with components in each external part of \(\Omega\). Note that the problem must be well-posed in \(\hat{\Omega}\);
        \item \(\hat{\Gamma} \subset \partial \hat{\Omega}\), when \(\partial \hat{\Omega}\) is an analytical boundary set verifying (2.) and \(\hat{\Gamma}\) is open in the \(\partial \hat{\Omega}\) topology.
    \end{enumerate}
    We denote the set of chosen source points by \(\mathcal{Y} = \{y_j \in \hat{\Gamma}: j=1,\dots,N\}\).
\end{definition}
Throughout this work, we will exclusively use the source set described in point \ref{source_set_definition_2} of Definition \ref{source_set_definition}. We make this choice as it consistently yields superior numerical results. However, it's worth noting that the density results presented remain applicable even when considering different types of admissible source sets.

Assuming that $\mathcal{L} = -\Delta$ and $\Phi$ is the fundamental solution of the Laplace equation, we are working with Dirichlet boundary conditions unless stated otherwise. It's important to highlight that the results stated below are also valid with different boundary conditions. In the appropriate functional space and given an admissible source set $\hat{\Gamma}$, consider the approximation space
\[
    \mathcal{S}(\Gamma, \hat{\Gamma}) = \Span\{\Phi(x-y)_{|x \in \Gamma} : y \in \hat{\Gamma}\}.
\]
Some preliminary results are going to be needed in order to present the desired density proofs.
We start by introducing the concept of analytic continuation. We refer to \cite{narasimhan2012complex} for more details.
\begin{definition}
    Let \(f\) be a complex-valued function defined on \(\Omega \subset \mathbb{C}\). We say that \(f\) is holomorphic on \(\Omega\) if for every \(a \in \Omega\), there exists a neighborhood \(U\) of \(a\) and \((c_n)_{n \in \mathbb{N}} \subset \mathbb{C}\) such that the power series
    \[
        \sum_{n=0}^{\infty} c_n(z-a)^n
    \]
    converges to \(f(z)\) for every \(z \in U\).
\end{definition}
\begin{theorem}[Analytic continuation]\label{ana_cont}
    Let \(f\) be a holomorphic function in the connected subset \(\Omega \subset \mathbb{C}\). If there exists a non-empty \(U \subset \Omega\) such that \(f = 0\) in \(U\), then \(f = 0\) in \(\Omega\).
\end{theorem}
As evident from the Remark \ref{chatp_numerical_remark_conv_motivation} above, the examination of layer potentials plays a pivotal role in the Method of Fundamental Solutions. Due to the depth of this topic, we refer to \cite{chen2010boundary}, \cite{kress2013linear}, and \cite{colton2013integral} for a more comprehensive understanding.

\begin{definition}\label{definition_single_and_double_layer_potentials}
    Let \(\Omega \subset \mathbb{R}^d\) be a bounded domain of class \(C^2\) and \(\varphi \in H^\frac{1}{2}(\partial\Omega)\). For $x \in \partial\Omega$, the functions
    \[
        S\varphi(x) = \int_{\partial\Omega} \Phi(x-y)\varphi(y) d\sigma(y)
    \]
    and
    \[
        M\varphi(x) = \int_{\partial\Omega} \frac{\partial \Phi(x-y)}{\partial n_y}\varphi(y) d\sigma(y)
    \]
    are called the single and double layer potentials associated with the operators $S$ and $M$ with density \(\varphi\), respectively.
\end{definition}
\begin{proposition}\label{sl_jump}
    Let \(\Omega  \subset \mathbb{R}^d\) be a bounded domain of class \(C^2\) and \(\varphi \in H^\frac{1}{2}(\partial\Omega)\). Then the single layer potential is harmonic in \(\mathbb{R}^d\setminus \overline{\partial\Omega}\), continuous across \(\partial\Omega\), and for every \(x \in \partial\Omega\) we have the following jump relations for the normal derivative:
    \[
        \frac{\partial S\varphi_\pm}{\partial n}(x) = \int_{\partial\Omega} \frac{\partial\Phi(x-y)}{\partial n_x}\varphi(y) d\sigma(y) \mp \frac{1}{2}\varphi(x),
    \]
    where
    $$\frac{\partial S \varphi_\pm}{\partial n}(x) \coloneq \lim_{h \rightarrow 0} n(x) \cdot \nabla S\varphi(x \pm h n(x))$$
    is to be understood in the sense of uniform convergence on $\partial\Omega$ and where the integral exists as an improper integral.
    In particular, we have
    \[
        \varphi(x) = \frac{\partial S\varphi_+}{\partial n}(x)-\frac{\partial S\varphi_-}{\partial n}(x), \; \forall x \in \partial\Omega.
    \]
    Analogously, the double layer potential is harmonic in \(\mathbb{R}^d\setminus \overline{\partial\Omega}\), its normal derivative is continuous across \(\partial\Omega\), and for every \(x \in \partial\Omega\) we have the following jump relations:
    \[
        M\varphi_\pm(x) = \int_{\partial\Omega} \frac{\partial\Phi(x-y)}{\partial n_y}\varphi(y) d\sigma(y) \pm \frac{1}{2}\varphi(x),
    \]
    where
    \[
        M\varphi_\pm(x) \coloneq \lim_{h \rightarrow 0} M\varphi(x \pm h n(x)).
    \]
    In particular, we have
    \[
        \varphi(x) = M\varphi(x)_+-M\varphi(x)_-, \; \forall x \in \partial\Omega.
    \]

% Lemma \ref{asymptotics_mfs_single_layer} describes the asymptotic behavior of the single layer potential.

% \begin{lemma}\label{asymptotics_mfs_single_layer}
%     Let \(\Omega \subset \mathbb{R}^2\) be an open and bounded set with \(C^2\) boundary and \(\varphi \in H^\frac{1}{2} (\partial\Omega)\). Then, the single layer potential
%     \begin{equation}\label{asymptotics_mfs_single_layer_proof_def_w}
%         w(x) = \int_{\partial\Omega} \Phi(x-y)\varphi(y) d\sigma(y)
%     \end{equation}
%     exhibits a logarithmic-growth at \(\infty\) given by
%     \[
%         w(x) = -\frac{M}{2\pi}\log(\abs{x}) + \mathcal{O}(1), \; \abs{x} \rightarrow \infty,
%     \]
%     where
%     \[
%         M = \int_{\partial\Omega} \varphi(y) d\sigma(y).
%     \]
% \end{lemma}
% \begin{proof}
%     First, since the logarithm is a concave function, one notices that by the Mean Value Theorem, inequality
%     \begin{equation}\label{asymptotics_mfs_single_layer_proof_log_in}
%         \log \frac{b}{a} < \frac{b-a}{a}
%     \end{equation}
%     holds for any \(a,b > 0\). Recalling that in \(\mathbb{R}^2\) the fundamental solution of the Laplace equation is \(\Phi(x) = -\frac{1}{2\pi}\log \abs{x}\), one can write
%     \[
%         -\frac{1}{2\pi}\log \abs{x-y} = -\frac{1}{2\pi}\log \frac{\abs{x-y}}{\abs{x}} -\frac{1}{2\pi} \log \abs{x}.
%     \]
%     Setting \(b=\abs{x-y}\) and \(a=\abs{x}\) in equation \eqref{asymptotics_mfs_single_layer_proof_log_in}, by the triangular inequality one finds that
%     \[
%         -\frac{1}{2\pi}\log \frac{\abs{x-y}}{\abs{x}} > -\frac{\abs{y}}{\abs{x}} \geq -C \frac{1}{\abs{x}} \implies \frac{1}{2\pi}\log \frac{\abs{x-y}}{\abs{x}} \leq C \frac{1}{\abs{x}}
%     \]
%     for some \(C >0\) such that \(\abs{y} \leq C, \forall y \in \partial\Omega\).
%     Therefore, equation \eqref{asymptotics_mfs_single_layer_proof_def_w} can be rewritten as
%     \[
%         w(x) = -\frac{1}{2\pi}\int_{\partial\Omega} \log \frac{\abs{x-y}}{\abs{x}}\varphi(y) d\sigma(y) -\frac{1}{2\pi}\int_{\partial\Omega} \log \abs{x} \varphi(y) d\sigma(y)
%     \]
% \end{proof}

\end{proposition}
Lastly, it will be useful to study the well-posedness of the exterior Dirichlet problem for the Laplace Equation, e.g. \cite{salsa2016partial}.
\begin{theorem}[Well-Posedness of the Exterior Dirichlet problem]
    Let \(\Omega\) be a bounded and open subset of \(\mathbb{R}^2\). Then, there exists a unique solution \(u \in C^2(\Omega^c) \cap C(\overline{\Omega^c})\) of the exterior Dirichlet Laplacian problem with boundary data \(g \in C(\partial\Omega)\) given by
    \[
        \begin{cases}
            \Delta u = 0, \text{ in } & \mathbb{R}^2\setminus \overline{\Omega}\\
            u = g, \text{ on } & \partial \Omega\\
            u(x) = \mathcal{O}(1), \text{ for } & \abs{x} \rightarrow \infty.
        \end{cases}
    \]
\end{theorem}

\begin{remark}
    Notice that the condition at infinity must be enforced to ensure uniqueness. For example, if considering null Dirichlet boundary conditions, one could easily find a family of solutions up to a multiplicative constant (if \(u(x)\) is a solution, then \(\alpha u(x)\) would also be a solution for any \(\alpha \in \mathbb{R}\)).
\end{remark}

The main result which justifies the \ac{MFS} for the Laplace equation is now stated. The proof given here is slightly different from the ones in \cite{bogomolny1985fundamental}, \cite{alves2009choice} and \cite{smyrlis2009applicability}. It is also influenced by the proofs in \cite{svilen_phd}.

\begin{theorem}\label{MFS_lap_dense}
    Let \(\Omega\) be an open and bounded set with \(C^2\) boundary \(\Gamma = \partial \Omega\) such that \(\overline{\Omega} \subset \hat{\Omega} \subset \mathbb{R}^2\), where \(\hat{\Omega}\) is an open and bounded set and \(\hat{\Gamma} = \partial \hat{\Omega}\) is an admissible source set. Then, \(\mathcal{S}(\Gamma, \hat{\Gamma}) \oplus \mathbb{R}\) is dense in \(H^\frac{1}{2}(\Gamma)\).
\end{theorem}
\begin{proof}
    Using the notation from Lemma \ref{banach_ortho_lemma}, consider $E=H^\frac{1}{2}(\Gamma)$. For every (fixed) \(y \in \hat{\Gamma}\), the maps \footnote{Here, $\Phi$ is used not only to represent the fundamental solution of the Laplace equation, but also the single layer potential $S$. This notation was used not only to emphasize that the fundamental solution centered in $y \in \hat{\Gamma}$ is in the space $H^{-\frac{1}{2}}(\Gamma)$ but also to remark that the action $\langle \Phi(\cdot - y), \varphi \rangle$ depends on $y$, contrary to the single layer potential in Definition \ref{definition_single_and_double_layer_potentials}.}
    \begin{align*}
        \Phi(\cdot-y)&: \varphi \mapsto \int_\Gamma \Phi(x-y)\varphi(x) d\sigma(x)\\
        1&: \varphi \mapsto \int_\Gamma \varphi (x) d\sigma(x)
    \end{align*}
    are linear and continuous in \(H^\frac{1}{2}(\Gamma)\), and \(1, \Phi(\cdot-y) \in H^{-\frac{1}{2}}(\Gamma)\) (notice that \(1, \Phi(\cdot-y) \in L^1_{\text{loc}}(\mathbb{R}^2)\) and \(1, \Phi(\cdot-y) \in L^2({\Gamma})\)).

    Let \(N = \mathcal{S}(\Gamma, \hat{\Gamma}) \oplus \mathbb{R} \subset H^{-\frac{1}{2}}(\Gamma)\). Using the Definition \ref{banach_ortho_def}, consider the set
    \[
         N^\perp = \{\varphi \in H^{\frac{1}{2}}(\Gamma): \langle \psi, \varphi \rangle = 0, \; \forall \psi \in N\},
    \]
    where the duality pairing \(\langle \cdot, \cdot \rangle\) generalizes the \(L^2\) inner product as explained in Remark \ref{preliminaries_chapter_duality_pairing_def_remark} and defined in \eqref{preliminaries_chapter_duality_pairing_def}.
    By Remark \ref{chapt_preliminaries_remark_density_banach}, it suffices to prove that \(N^\perp = \{0\}\). Let \(\varphi \in N^\perp\) and define
    \[
        w(y) = \int_\Gamma\Phi(x-y)\varphi(x) d\sigma(x), \; y \in \mathbb{R}^2.
    \]
    Since \(\varphi \in N^\perp\), then
    \begin{equation}\label{dens_ext_lap_bound}
        \int_\Gamma\Phi(x-y)\varphi(x) d\sigma(x) = 0, \; \forall y \in \hat{\Gamma}\\
    \end{equation}
    and
    \begin{equation}\label{dens_ext_lap}
        \int_\Gamma \varphi (x) d\sigma(x) = 0.
    \end{equation}
    In order to verify that \(w(y)\) satisfies the exterior Laplace problem with Dirichlet boundary conditions, one uses the fact that \(w\) exhibits the asymptotic behavior (see Chapter 6 of \cite{kress2013linear})
    \[
        w(y) = -\frac{1}{2 \pi} \int_\Gamma \varphi (x) d\sigma(x) \log \abs{y} + \mathcal{O}(1), \; \abs{y} \rightarrow \infty
    \]
    and condition \eqref{dens_ext_lap}, to check that \(w\) is bounded at infinity. Therefore, by condition \eqref{dens_ext_lap_bound}
    \[
        \begin{cases}
            \Delta w = 0, \text{ in } \mathbb{R}^2\setminus \hat{\Omega}\\
            w(y) = 0, \text{ on } \hat{\Gamma}\\
            w(y) = \mathcal{O}(1), \abs{y} \rightarrow \infty.
        \end{cases}
    \]
    Since the problem above is well-posed, it has a unique solution \(w(y) = 0, \; \forall y \in \mathbb{R}^2\setminus\overline{\hat{\Omega}}\). By (a unique) analytic continuation (see Theorem \ref{ana_cont}), one can extend \(w\) by zero in \(\mathbb{R}^2\setminus\overline{\Omega}\). Since \(w\) is a single layer potential over \(\Gamma\), \(w\) is continuous on \(\Gamma\) and therefore, by continuity, \(w = 0\) on \(\Gamma\). Once again, using the fact that the single layer potential is harmonic in \(\Omega\), \(w\) satisfies the (interior) Laplace problem
    \[
        \begin{cases}
            \Delta w = 0, \text{ in } \Omega\\
            w(y) = 0, \text{ on } \Gamma
        \end{cases}
    \]
    which, by uniqueness, implies that \(w = 0\) in \(\Omega\) and consequently in \(\mathbb{R}^2\). Finally, we can conclude that \(\varphi = 0\) in \(\Gamma\) by Proposition \ref{sl_jump} since the normal derivate jump is zero.

    Therefore, \(N^\perp = \{0\}\) and by Lemma \ref{banach_ortho_lemma}
    \[
        \mathcal{S}(\Gamma, \hat{\Gamma}) \oplus \mathbb{R} = \{0\}^\perp
    \]
    given that \(H^\frac{1}{2}(\Gamma)\) is reflexive. Since \(0 \in H^\frac{1}{2}(\Gamma)\) (and \(0 \in H^{-\frac{1}{2}}(\Gamma)\)) then \(\mathcal{S}(\Gamma, \hat{\Gamma}) \oplus \mathbb{R}\) is dense in \(H^\frac{1}{2}(\Gamma)\) and in \(H^{-\frac{1}{2}}(\Gamma)\) (this is to be expected since \(H^{s}(\Omega)\) is dense in \(H^{-s}(\Omega)\) for \(s > 0\)).
\end{proof}

\begin{remark}\label{remark_density_sequence_density_layers}
    Theorem \ref{MFS_lap_dense} guarantees the existence of a sequence of density functions $\{\varphi_n\} \subset H^{\frac{1}{2}}(\Gamma)$ and a sequence of constants $\{c_n\} \subset \mathbb{R}$ such that the modified single-layer potential
    \[
    \hat{\mathcal{S}}\varphi_n(y) = \int_{\hat{\Gamma}} \Phi(x-y)\varphi_n(x) d\sigma(x) + c_n
    \]
    converges to the Dirichlet boundary data $g$ in $H^\frac{1}{2}(\Gamma)$, i.e.,
    \[
    \|{\hat{\mathcal{S}}\varphi_n}_{|\Gamma} - g\|_{H^\frac{1}{2}(\Gamma)} \rightarrow 0, \; n \rightarrow \infty.
    \]

    Since $\hat{\mathcal{S}}\varphi_n$ is harmonic for each $n \in \mathbb{N}$, it allows us to approximate any interior Laplace Dirichlet \ac{BVP}. Conversely, for any $\varphi \in H^\frac{1}{2}(\Gamma)$ and $c \in \mathbb{R}$, they define a \ac{BVP} whose solution is given by the associated modified single-layer potential $\hat{\mathcal{S}}\varphi$, with boundary data determined by its restriction to \(\Gamma\).

\end{remark}

The density proof for the transmission/decomposition problem directly follows from Theorem \ref{MFS_lap_dense} and the equivalence formulation presented in Theorem \ref{equivalence_transmission}. In Chapter \ref{chap:implement}, we specifically consider the case \(f_1=f_2=1\) in equations \eqref{decomp_prob}. Thus, we introduce the source function
\begin{equation}
    f = \begin{cases}
        \frac{1}{k_1}, & \text{in } \Omega_1\\
        \frac{1}{k_2}, & \text{in } \Omega_2\\
    \end{cases}
\end{equation}
and let \(u \in H^1_0(\Omega)\) represent the associated unique weak solution to the Poisson equation with Dirichlet boundary conditions and a (discontinuous) source function \(f\) as in equation \eqref{decomp_poisson}. According to Theorem \ref{equivalence_transmission}, the restriction of \(u\) to each subdomain uniquely solves the weak form of
\begin{align}\label{transmission_restriction_equations_density}
    \begin{cases}
    - \Delta u_i = \frac{1}{k_i}, & \text{in }\Omega_i\\
    u_1 - u_2 = 0, & \text{on }\gamma\\
    k_1 \frac{\partial u_1}{\partial \mathbf{n_1}} + k_2 \frac{\partial u_2}{\partial  \mathbf{n_2}} = 0, & \text{on }\gamma\\
    u_i = 0, & \text{on }\Gamma_i
    \end{cases}
    ,\qquad
    \text{where }
    u = \begin{cases}
        u_1, & \text{in } \Omega_1\\
        u_2, & \text{in } \Omega_2\\
    \end{cases}
\end{align}
and \(u_i \in H^1(\Omega_i)\) for \(i=1, 2\).

Since \(H^\frac{1}{2}(\partial \Omega_i)\) is the trace space of \(H^1(\Omega_i)\), and the normal derivatives of \(u_i\) belong to the space \(H^{-\frac{1}{2}}(\partial\Omega_i)\) (as seen in the final part of subchapter \ref{lebesgue_and_sobolev_preliminaries}), one can apply Theorem \ref{MFS_lap_dense} to each subdomain in equation \eqref{transmission_restriction_equations_density}. This allows us to find a sequence of density layers \(\{\varphi^{(n)}_i\} \subset H^{\frac{1}{2}}(\partial\Omega_i)\) such that
\begin{align*}
    &\norm{{\hat{\mathcal{S}}\varphi^{(n)}_i}_{|\partial\Omega_i} - u_i}_{H^\frac{1}{2}(\partial\Omega_i)} \rightarrow 0, \; n \rightarrow \infty,\\
    &\norm{{M\varphi^{(n)}_i}_{|\partial\Omega_i} - \frac{\partial u_i}{\partial n_i}}_{H^{-\frac{1}{2}}(\partial\Omega_i)} \rightarrow 0, \; n \rightarrow \infty,
\end{align*}
where \(\hat{\mathcal{S}}\) is defined in Remark \ref{remark_density_sequence_density_layers}, and \(M\) is the double-layer potential in Definition \ref{definition_single_and_double_layer_potentials} (see Remark \ref{density_remark_general_bc_and_hilbert} for more details on how different boundary conditions can be handled). Consequently, given the equivalence between both problems, it is possible to approximate the solution \(u\) of the Poisson equation with a discontinuous source term using the \ac{MFS} via the decomposition approach\footnote{One important detail was overlooked: while the density result in \ref{MFS_lap_dense} is independent of the \ac{MFS}, by construction it is only applicable to harmonic functions. Nevertheless, one can always find a non-homogeneous solution and transform the problem into a homogeneous \ac{PDE} by adjusting the boundary conditions accordingly. Chapter \ref{chap:implement} presents a more detailed approach.}.

Finally, the discretization argument follows from the fact that for a set of source points \(\mathcal{Y} = \{y_1,\dots, y_N\} \subset \mathbb{R}^2\setminus\overline{\Omega}\), the fundamental solutions \(\Phi(\cdot-y_1),\dots,\Phi(\cdot-y_N)\) are linearly independent on \(\partial \Omega\) and, consequently, in \(\Omega\).

\begin{theorem}\label{lapl_li}
    Let \(\mathcal{Y}\) be a set of source points, as defined above. Then, the restriction of the functions \(\Phi(\cdot-y_1),\dots,\Phi(\cdot-y_N)\) to \(\partial\Omega\) are linearly independent.
\end{theorem}
\begin{proof}
    Assume that \(\tilde{u}(x) = \sum_{j=1}^{N}\alpha_j \Phi(x-y_j) = 0, \; \forall x \in \partial\Omega\). We prove that \(\alpha_1=\dots=\alpha_N = 0\). Since, by construction, \(\tilde{u}\) satisfies the Laplace equation and by assumption \(\tilde{u}(x) = 0, \; \forall x \in \partial\Omega\), by the well-posedness of the interior Dirichlet problem, \(\tilde{u} = 0\) in \(\overline{\Omega}\). Again, by analytic continuation, \(\tilde{u} = 0\) in \(\mathbb{R}^2\setminus\mathcal{Y}\). Applying the Laplace operator to \(\tilde{u}\), by linearity
    \[
        \sum_{j=1}^{N}\alpha_j \delta{y_j} = 0
    \]
    which implies that \(\alpha_1=\dots=\alpha_N = 0\) by the linear independence of the Dirac deltas.
\end{proof}

Now consider the operator \(\mathcal{L} = -(\Delta + k^2)\), and assume that \(k\) is \textbf{not} an eigenfrequency of the Helmholtz equation in \(\Omega\) (for the exterior problem, instead of using the term \textit{eigenfrequency}, one says \textit{scattering resonance}). The results presented for the fundamental solution of the Laplace Equation still hold for the fundamental solution of the Helmholtz equation. However, a different type of conditions at infinity must be considered, as discussed in \cite{colton2013integral}.

\begin{theorem}[Well-Posedness of the Exterior Dirichlet problem of the Helmholtz Equation]
    Let \(\Omega\) be a bounded and open subset of \(\mathbb{R}^2\) and assume that \(k\) is positive. Then, there exists a unique solution \(u \in C^2(\Omega^c) \cap C(\overline{\Omega^c})\) of the exterior Dirichlet Helmholtz problem with boundary data \(g \in C(\partial\Omega)\) given by
    \[
        \begin{cases}
            -\Delta u = k^2 u, & \text{ in }  \mathbb{R}^2\setminus \overline{\Omega}\\
            u = g, & \text{ on }  \partial \Omega\\
            \abs{x} \left(\frac{x}{\abs{x}}\nabla u(x) - i k\right)u(x) = 0, & \text{ for }  \abs{x} \rightarrow \infty.
        \end{cases}
    \]
\end{theorem}

\begin{remark}\label{sommerfeld_conditions}
    Just like the exterior Dirichlet problem for the Laplace Equation, the well-posedness of the exterior Helmholtz Problem depends on conditions at infinity. In this case, they are known as the \textit{Sommerfeld Radiation Conditions} and are expressed as
    \[
        \abs{x}^\frac{d-1}{2} \left(\frac{x}{\abs{x}}\nabla u(x) - i k \right)u(x) = 0, \text{ as } \; \abs{x} \rightarrow \infty,
    \]
    where \(d\) represents the spatial dimension. It's worth noting that the single-layer potential defined as
    \[
        \int_\Gamma \Phi_k(x-y) \varphi(x) d\sigma(x)
    \]
    also satisfies the Sommerfeld Radiation Condition as \(\abs{y} \rightarrow \infty\).
\end{remark}

Analogously to the Laplace problem, consider the space
\[
    \mathcal{S}(\Gamma, \hat{\Gamma}) = \Span\{\Phi_k(x-y)_{|x \in \Gamma} : y \in \hat{\Gamma}\}.
\]
Again, like in Theorem \ref{MFS_lap_dense}, we point the reader to \cite{alves2009choice}, \cite{svilen_phd} and \cite{alves2005new}, where slightly different proofs are stated.

\begin{theorem}\label{MFS_helm_dense}
    Assume that \(k\) is positive and let \(\Omega\) be an open and bounded set with \(C^2\) boundary \(\Gamma = \partial \Omega\) such that \(\overline{\Omega} \subset \hat{\Omega} \subset \mathbb{R}^2\), where \(\hat{\Omega}\) is an open and bounded set and \(\hat{\Gamma} = \partial \hat{\Omega}\) is an admissible source set. Then, \(\mathcal{S}(\Gamma, \hat{\Gamma})\) is dense in \(H^\frac{1}{2}(\Gamma)\).
\end{theorem}

\begin{proof}
    This proof follows the same steps as in the proof of Theorem \ref{MFS_lap_dense}. As before, let \(E = H^\frac{1}{2}(\Gamma)\). For every (fixed) \(y \in \hat{\Gamma}\), the map
    \[
        \Phi_k(\cdot-y): \varphi \mapsto \int_\Gamma \Phi_k(x-y)\varphi(x)d\sigma(x)
    \]
    is linear and continuous in \(H^\frac{1}{2}(\Gamma)\) and \(\Phi_k(\cdot-y) \in H^{-\frac{1}{2}}(\Gamma)\). Let \(N = \mathcal{S}(\Gamma, \hat{\Gamma})\) and
    \[
        N^\perp = \{\varphi \in H^\frac{1}{2}(\Gamma): \langle \psi, \varphi \rangle = 0, \psi \in N\}.
    \]
    Once again, it suffices to prove that \(N^\perp = \{0\}\), i.e., given \(\varphi \in H^\frac{1}{2}(\Gamma)\) the implication
    \[
        \forall y \in \hat{\Gamma}, \, \int_\Omega \Phi_k(x-y)\varphi(x)d\sigma(x) = 0 \implies \varphi(x) = 0, \; \forall x \in \mathbb{R}^2
    \]
    holds and define
    \[
        w(y) = \int_\Gamma \Phi_k(x-y)\varphi(x)d\sigma(x).
    \]
    Given that \(w\) satisfies the Sommerfeld Radiation Conditions and, by assumption, \(w(y) = 0\) in \(\hat{\Gamma}\), then \(w = 0\) in \(\mathbb{R}^2\setminus\Omega\) is the unique solution of the exterior Dirichlet problem of the Helmholtz equation
    \[
        \begin{cases}
            -\Delta w = k^2 w, & \text{ in } \mathbb{R}^2\setminus \overline{\Omega}\\
            w = 0, & \text{ on } \partial \Omega\\
            \abs{y} (\frac{y}{\abs{x}}\nabla w(y) - i k)u(x) = 0, & \text{ for } \abs{y} \rightarrow \infty,
        \end{cases}
    \]
    since \(k > 0\) is not a scattering ressonance. By analytic continuation, one can extend \(w\) by zero to \(\mathbb{R}^2\setminus \overline{\Omega}\). The rest of the proof is the same as in the Theorem \ref{MFS_lap_dense}, using the fact that \(k\) is not an eigenfrequency of \(\Omega\), the interior Dirichlet problem is well-posed.
\end{proof}
\begin{remark}\label{density_remark_general_bc_and_hilbert}
    In both Theorem \ref{MFS_lap_dense} and Theorem \ref{MFS_helm_dense}, the density proof can be extended to \(H^s(\Gamma)\) for \(s > \frac{1}{2}\). However, in practical applications, we are primarily interested in the case \(s = \frac{1}{2}\). It's worth noting that when \(s = 0\), there's no need to invoke the Hahn-Banach Theorem since \(H^0(\Gamma) = L^2(\Gamma)\), which is a Hilbert Space. In such cases, we can rely on Corollary \ref{hilb_dense}.

    For situations involving general boundary conditions, the proofs presented above follow the same logical framework. One should consider the appropriate approximating set \(\mathcal{S}(\Gamma, \hat{\Gamma})\) and the corresponding integral operator. For example, in the case of Neumann boundary conditions, the set \(\mathcal{S}(\Gamma, \hat{\Gamma})\) would be defined as
    \[
    \mathcal{S}(\Gamma, \hat{\Gamma}) = \Span\{\partial_n \Phi(x-y)_{|x \in \Gamma} : y \in \hat{\Gamma}\},
    \]
    accompanied by the use of the double-layer potential \(M\varphi\). It's important to note that \(\partial_n u = g \in H^{-\frac{1}{2}}(\Gamma)\) in these scenarios.
\end{remark}

Once again, the discretization argument relies on the linear independence of the functions \(\Phi_k(\cdot-y_1),\dots,\Phi_k(\cdot-y_N)\), where \(y_1,\dots,y_N \in \mathbb{R}^2\setminus\overline{\Omega}\) are distinct source points. The proof follows the same logic as presented in Theorem \ref{lapl_li} and from the fact that \(k\) is not an eigenfrequency of \(\Omega\).

Before stating the results regarding the convergence and stability of the \ac{MFS} for the Laplace and Helmholtz equations, we address the issue of source point placement. Various methods for this purpose are discussed in \cite{alves2009choice}. In this work, we adopt the approach outlined in point \ref{source_set_definition_2} of Definition \ref{source_set_definition} for the source points placement. To illustrate this method, consider \(\Gamma = \partial \Omega\) and the equally spaced collocation points \(x_1,\dots,x_M \in \Gamma\). We then approximate the outward normal vector \(\tilde{\mathbf{n}}_i\) at the point \(x_i\) using the formula
\[
    \tilde{\mathbf{n}}_i = \frac{(x_i - x_{i-1})^\perp }{2} + \frac{(x_{i+1}-x_i)^\perp }{2},
\]
with the orthogonal notation \(z^\perp = (-z_2,z_1)\). Using this, we can further approximate the unit normal vector as \(\mathbf{n}_i = \frac{\tilde{\mathbf{n}_i}}{\abs{\tilde{\mathbf{n}_i}}}\), and define the source point \(y_i\) as
\[
    y_i = x_i + \eta \mathbf{n},
\]
where \(\eta>0\) (with its sign depending on the orientation of the boundary's parameterization) is a small coefficient controlling the distance between the boundary \(\Gamma\) and the artificial boundary \(\hat{\Gamma}\). As we will discuss below, this coefficient significantly impacts the convergence of the \ac{MFS}, with larger values of \(\eta\) potentially yielding better approximations. However, this approach is most effective for simple geometries, as it can increase the condition number of the matrix \(A\), denoted by \(\kappa(A)\).


\section{Numerical approach for the Laplace Equation}\label{n_a_MFS_lap}
Based on the results presented in the previous subsection, we can now proceed with the numerical solution of both the Laplace and Helmholtz equations for (Dirichlet, Neumann,\dots) boundary data \(g\), provided we can determine the coefficients in the discretization of the single-layer potential. For simplicity, we will continue to assume Dirichlet boundary conditions. Let \(N\) denote the number of source points, and \(M\) represent the number of collocation points on the boundary, labeled as \(x_i\) with \(i=1,\dots, M\). We proceed by solving the discretized equation
\[
    \tilde{u}(x_i) = \sum_{j=1}^{N} \alpha_j \Phi(x_i-y_j) + \alpha_{N+1} = g(x_i)
\]
with respect to the coefficients \(\alpha_j\). Defining \(g_i \coloneq g(x_i), \, i=1,\dots, M\), notice that the equation above can be rewritten in the matrix form
\begin{equation}\label{MFS_m_system}
    {\underbrace{\begin{bmatrix}
        \Phi(x_1, y_1) & \cdots & \Phi(x_1, y_N) & 1 \\
        \vdots & \ddots & \vdots & \vdots\\
        \Phi(x_M, y_1) & \cdots & \Phi(x_M, y_N) & 1
    \end{bmatrix}}_{A}}_{M\times (N+1)}
    {\underbrace{\begin{bmatrix}
        \alpha_1\\
        \vdots\\
        \alpha_N\\
        \alpha_{N+1}
    \end{bmatrix}}_\alpha}_{(N+1)\times 1}
    =
    {\underbrace{\begin{bmatrix}
        g_1\\
        \vdots\\
        g_M
    \end{bmatrix}}_g}_{M\times 1}
\end{equation}

It is important to note that when \(M < N+1\), we have an under-determined system of equations. Consequently, the number of collocation points must be greater than the number of source points. This situation can be framed in two distinct ways:
\begin{itemize}
    \item if \(N+1=M\), we encounter an interpolation problem where we solve a linear system consisting of \(N\) equations with \(N\) unknowns;

    \item when \(M > N+1\), we must address a least-squares problem. This approach is adopted in this work as it avoids interpolation instabilities, enforces boundary conditions at specific points, and exhibits robustness, especially when dealing with irregular boundary data. Following numerous numerical experiments, as detailed in \cite{alves2009choice}, it was established that \(M=2N\) is a suitable choice for both the number of source and collocation points.
\end{itemize}

It's important to recall that various boundary conditions can be considered. For instance, when solving the Laplace equation with Neumann boundary conditions, the entries \(\Phi(x_i,y_j)\) should be replaced with \(\partial_{n_x}\Phi(x_i,y_j) = \nabla_x\Phi(x_i,y_j)\cdot \mathbf{n}_i\), where \(\mathbf{n}_i\) represents the unit normal vector at the boundary point \(x_i\).

Now, we present some results concerning the convergence and stability of the \ac{MFS} for the Laplace equation with Dirichlet boundary conditions. These results are specifically derived for a disk-shaped domain \(\Omega\) with a circular artificial boundary \(\hat{\Gamma} = \partial \hat{\Omega}\). Let \(\rho\) denote the radius of \(\Omega\), \(R\) the radius of \(\hat{\Omega}\), and assume that \(N=M\).

\begin{theorem}\label{MFS_lap_conv}
    Assume that \(R^N - \rho^N \neq 1\). Then,
    \begin{enumerate}
        \item the matrix \(A\) is non-singular;
        \item if \(R \neq 1\) and the boundary data \(g\) is real and analytic, then the exact solution \(u\) of the Laplace equation admits a harmonic extension to some neighborhood of \(\overline{\Omega}\). Therefore, one may assume that \(u\) is harmonic in \(0 \leq r \leq r_0\) for some \(r_0 \geq \rho\). In this case, there exists \(C > 0\) and \(c \in (0, 1)\) which are independent of \(N\) and \(u\) such that
        \[
            \sup_{\substack{x \in \overline{\Omega}}} \abs{u(x) - \tilde{u}(x)} \leq C c^N \sup_{\substack{\abs{x}\leq r_0}}\abs{u(x)}.
        \]
    \end{enumerate}
\end{theorem}

Theorem \ref{MFS_lap_conv} provides some insights into the \ac{MFS}. Firstly, it's essential to note that this method exhibits \textit{exponential convergence} concerning the number of source points, which is quite remarkable. In fact, the term \(c\) depends on the distance between \(\Gamma\) and the artificial boundary \(\hat{\Gamma}\), controlled by the coefficient \(\eta\), and is defined as

\[
c = \begin{cases}
        \frac{\rho}{R}, & \text{if } r_0 > \frac{R^2}{\rho}\\
        \sqrt{\frac{\rho}{R}}, & \text{if } r_0 < \frac{R^2}{\rho}.
    \end{cases}
\]

However, one of the main drawbacks of the \ac{MFS} is the ill-conditioning of the matrix \(A\), along with the fact that this matrix is dense, making it unsuitable for the utilization of optimized sparse software solvers for the system \eqref{MFS_m_system}. In particular, while larger values of the parameter \(\eta\) enable better numerical approximations, they also lead to an exponential increase\footnote{It's important to note that the ill-conditioning of the matrix \(A\) is associated with the classical basis functions used in the \ac{MFS}. Nonetheless, it is possible to derive basis functions that, after certain modifications, do not exhibit the same limitations and have a condition number \(\kappa(A)\) of \(\mathcal{O}(1)\). We refer to \cite{antunes2018reducing} and \cite{antunes2018numerical} for more information.} in the condition number \(\kappa(A)\), as documented in \cite{christiansen1981condition}, \cite{kitagawa1988numerical}, and \cite{kitagawa1991asymptotic}.

\begin{theorem}
    In the conditions of the Theorem \ref{MFS_lap_conv}, the condition number \(\kappa(A)\) can be estimated by
    \[
        \kappa(A) \sim \frac{\log R}{2}N \left(\frac{R}{\rho}\right)^{\frac{N}{2}}.
    \]
\end{theorem}

Another interesting point to note is the condition \(R \neq 1\), which is directly related to the space \(\mathcal{S}(\Gamma, \hat{\Gamma}) \oplus \mathbb{R}\) that was proven to be dense in \(H^\frac{1}{2}(\Gamma)\) in Theorem \ref{MFS_lap_dense}. Suppose \(R=1\) and \(\hat{\Omega}\) is a disk with radius \(R\) containing the origin. In such a case, if we exclude the constant basis function \(1\), then
\[
\tilde{u}(0) = \sum_{j=1}^{N}\alpha_j \Phi(0-y_j) = -\frac{1}{2\pi}\sum_{j=1}^{N}\alpha_j \log(R) = 0,
\]
regardless of the choice of source points on \(\hat{\Gamma}\). Consequently, it becomes impossible to approximate any non-zero harmonic function at the origin. However, this limitation is overcome when we include the basis function \(1\), as it was used to establish the density result. While this rarely affects the numerical approximations in the subsequent chapters, it is nevertheless included for the sake of consistency. This is why a column of ones was added to the matrix \(A\).

\subsection{An enrichment technique}\label{m_particular_solutions}

Before diving into the numerical approach for the Helmholtz equation, we introduce some modifications to the classical \ac{MFS} method presented in the previous subsection. There is another drawback in our method: our basis functions are analytical and might lose precision when approximating functions that display singularities, for example near a corner if the domain is not smooth. In what follows we introduce an enrichment technique with particular solutions\footnote{\label{particular_solutions_footnote} The terminology \textit{particular solutions} agrees with the references \cite{betcke2005reviving}, \cite{antunes2010meshfree}, and \cite{barnett2008stability}, and it does not refer to the solution of a non-homogeneous \ac{PDE}, which is also called a \textit{particular solution}. To avoid confusion, the latter will be referred to as a \textit{non-homogeneous} solution.} that allows for singularity treatment. In the same vein as in Proposition \ref{dirac_not_polar}, consider a wedge-like domain with interior angle \(\Theta\).

\begin{figure}[H]
\centering
\begin{tikzpicture}
    % Coordinates of the triangle vertices
    \coordinate[label=left:O] (O) at (0,0);
    \coordinate[label=right:A] (A) at (3,0);
    \coordinate[label=above:B] (B) at (1.5,2.5);

    % Drawing the triangle
    \draw (O) -- (A);
    \draw (O) -- (B);
    % Labeling the angle
    \draw (0.6,0) arc (0:60:0.6);
    \node at (0.8,0.3) {$\Theta$};
    \draw [decorate, decoration={snake, amplitude=0.3mm, segment length=4.5mm}] (A) to[out=45, in=0] (B);
\end{tikzpicture}
\caption{A wedge-like ``shape'' with an interior angle \(\Theta\).}\label{wedge}
\end{figure}
Consider the Laplace equation in polar coordinates, given by
\begin{equation}\label{lap_polar}
    \left(\partial_r^2 + \frac{1}{r} \partial_r +\frac{1}{r^2}\partial_\theta^2\right)u(r,\theta) = 0, \quad r>0, \; 0 \leq \theta \leq \Theta.
\end{equation}
Then, by separation of variables \(u(r, \theta) = R(r) T(\theta)\), one can find two different families of particular solutions given by
\[
    u(r,\theta) = \left(c_1 r^\alpha + c_2 r^{-\alpha}\right) \times \left(c_3 \cos(\alpha \theta) + c_4 \sin(\alpha \theta)\right), \; \alpha >0
\]
or
\[
    u(r,\theta) = \left(c_1 \log (r) + c_2 \right) \times \left(c_3 \theta + c_4 \right),
\]
where \(c_1, c_2, c_3, c_4 \in \mathbb{C}\). To find \(\alpha\), one must take into account the amplitude of the angle \(\Theta\) and the boundary conditions at each segment \(\overline{OA}\) and \(\overline{OB}\). We summarize the asymptotic harmonic solutions of \eqref{lap_polar} in Appendix \ref{chapter:appendixB}.
% \begin{itemize}
%     \item For Dirichlet-Dirichlet boundary conditions given by \(u(r, 0) = A, u(r, \Theta) = B\), then \(\alpha_k = \frac{k \pi}{\Theta}\) and
%     \[
%         u(r, \theta) = A (B-A)\frac{\theta}{\Theta} + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\sin(\alpha_k \theta);
%     \]
%     \item For Dirichlet-Neumann boundary conditions given by \(u(r, 0) = A, \partial_n u(r, \Theta) = B\), then \(\alpha_k = \frac{\left(k+\frac{1}{2}\right) \pi}{\Theta}\) and
%     \begin{itemize}
%         \item If \(\Theta \neq \frac{\pi}{2}, \frac{3 \pi}{2}\),
%         \[
%             u(r, \theta) = A + \frac{B}{\cos(\Theta)} r \sin (\theta) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\sin(\alpha_k \theta);
%         \]
%         \item If \(\Theta = \frac{\pi}{2}, \frac{3 \pi}{2}\),
%         \[
%             u(r, \theta) = A + (-1)^{l+1}\frac{B r}{\Theta}\left(\log(r) \sin(\theta) + \theta \cos(\theta) \right) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\sin(\alpha_k \theta),
%         \]
%         with \(l = 0\) if \(\Theta = \frac{\pi}{2}\) and \(l = 1\) if \(\Theta = \frac{3\pi}{2}\);
%     \end{itemize}
%     \item For Neumann-Dirichlet boundary conditions given by \(\partial_n u(r, 0) = A, u(r, \Theta) = B\), then \(\alpha_k = \frac{\left(k+\frac{1}{2}\right) \pi}{\Theta}\) and
%     \begin{itemize}
%         \item If \(\Theta \neq \frac{\pi}{2}, \frac{3 \pi}{2}\),
%         \[
%             u(r, \theta) = B - A r \sin(\theta) + \frac{A \sin (\Theta)}{\cos(\Theta)}r \cos(\theta) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\cos(\alpha_k \theta);
%         \]
%         \item If \(\Theta = \frac{\pi}{2}, \frac{3 \pi}{2}\),
%         \[
%             u(r, \theta) = B - \frac{A r}{\Theta}\left(\log(r) \cos(\theta) - \theta \sin(\theta) \right) - A r \sin(\theta) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\cos(\alpha_k \theta);
%         \]
%     \end{itemize}
%     \item For Neumann-Neumann boundary conditions given by \(\partial_n u(r, 0) = A, \partial_n u(r, \Theta) = B\), then \(\alpha_k = \frac{k \pi}{\Theta}\) and
%     \begin{itemize}
%         \item If \(\Theta \neq \pi, 2\pi\),
%         \[
%             u(r, \theta) = -A r \sin(\theta) - \frac{B + A \cos (\Theta)}{\sin(\Theta)}r \cos(\theta) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\cos(\alpha_k \theta);
%         \]
%         \item If \(\Theta = \pi, 2\pi\),
%         \[
%             u(r, \theta) = -A r \sin(\theta) + \frac{(-1)^l B - A}{\Theta} r \left(\log(r) \cos(\theta) - \theta \sin(\theta) \right) + \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\cos(\alpha_k \theta);
%         \]
%         with \(l = 0\) if \(\Theta = \pi\) and \(l = 1\) if \(\Theta = 2\pi\).
%     \end{itemize}
% \end{itemize}

% \begin{remark}\label{particular_solutions}
%     Observe that if the wedge domain is rotated by some angle \(\theta_1\) (see Figure \eqref{rotated_wedge}) one can consider the translation \(\theta^\star = \theta - \theta_1\), where \(\theta^\star\) is the angle on the "correct" wedge domain, see Figure \eqref{wedge}.
%     \begin{figure}[H]
%         \centering
%         \includegraphics[scale=0.5]{Images/rotated_wedge.png}
%         \caption{Rotation of the wedge domain. Image taken from \cite{li2000singularities}.}
%         \label{rotated_wedge}
%     \end{figure}
%     In applications, we are mostly concerned with Dirichlet-Neumann and Neumann-Dirichlet boundary conditions. Just like stated above, some of these boundary conditions have different expansions for the angles \(\Theta=\frac{\pi}{2}\) and \(\Theta=\frac{3\pi}{2}\). However, we are only concerned with the expansion
%     \[
%         v(r,\theta) = \sum_{k=0}^{\infty}\alpha_k r^{\alpha_k}\psi(\alpha_k \theta)
%     \]
%     where \(\psi=\sin\) or \(\psi = \cos\). In these cases, if we neglect the other terms, for the special angle \(\Theta = \frac{\pi}{2}\) above we would find that \(\alpha_k \in \mathbb{N}\). Without going into much dep2t in singularity analysis, then its partial derivative \(\partial_r v(r,\theta)\) would be of the form
%     \[
%         \partial_r v(r,\theta) = \sum_{k=0}^{\infty}\alpha_k^2 r^{\alpha_k-1}\psi(\alpha_k \theta)
%     \]
%     where \(\alpha_k-1 \in \mathbb{N}\). In general, if \(\alpha_k \in \mathbb{N}\) for some angle \(\Theta\) then all of its derivatives are continuous and \(v(r,\theta)\) is analytical. More precisely, there is no singularity in these cases. Therefore, one does not need to enrich the set of basis functions since the fundamental solutions correctly reproduce the behavior near the corner's tip. Such corners are called \textit{regular}. On the other hand, corners that present singularities are called \textit{singular} and are the ones that we are interested to approximate.

%     Also notice that, in the expansions above, the term \(r^{-\alpha_k}\) does not appear. This has to do with the fact we are dealing with an interior problem: when considering the exterior problem, the terms \(r^{\alpha_k}\) are replaced with \(r^{-\alpha_k}\) (observe that it satisfies the asymptotic conditions prescribed in order to have well-posedness!).
% \end{remark}

To incorporate the singular behavior near a corner with less regularity and (possible) singularities\footnote{We discuss another matter related to terminology. In the literature, these types of corners are often referred to as "singular corners." However, this terminology is problematic (as there is no such thing as a "singular corner"). Therefore, whenever we encounter such corners, we explicitly describe them as "less regular corners" or "corners with potential singularities".}, first assume, without loss of generality, that the domain \(\Omega\) has just one corner and that the solution of our \ac{BVP} can be decomposed in regular and singular parts,
\[
    u(x) = u_R(x) + u_S(x), \; x \in \overline{\Omega},
\]
where \(u_R\) is the regular part approximated by the \ac{MFS} basis functions and the singular part \(u_S\) is approximated by Fourier expansions using the families of particular solutions above, having the boundary conditions into account. Let \(\phi_s(r, \theta)\) be one of those expansions centered at the corner's tip, where \(s\) is the order of the expansion. Then, the numerical approximation can be written as
\begin{equation}
    \tilde{u}(x) = \sum_{j=1}^{N}\alpha_j \Phi(x-y_j) + \alpha_{N+1} + \sum_{s=1}^{P} \beta_s \phi_s(r(x),\theta(x)), \; x \in \overline{\Omega}.
\end{equation}
Considering the collocation points \(x_1,\dots,x_M \in \partial \Omega\), the linear system of equations \eqref{MFS_m_system} can be generalized to
\begin{equation}
    {\underbrace{\bigg[ \begin{array}{c | c}
        A_1 & B_1 \\
    \end{array} \bigg]}_{A}}_{M\times(N+1+P)}
    \begin{bmatrix}
        \alpha\\
        \beta
    \end{bmatrix}_{(N+1+P)\times 1}
    =
    \bigg[ \begin{array}{c}
        g \\
    \end{array} \bigg]_{M\times 1},
\end{equation}
where the block matrix \(A_1\) is the matrix \(A\) in \eqref{MFS_m_system} and the \(B_1\) block matrix is given by
\[
    B_1=\begin{bmatrix}
        \phi_1(r(x_1), \theta(x_1)) & \cdots & \phi_P(r(x_1), \theta(x_1)) \\
        \vdots & \ddots & \vdots\\
        \phi_1(r(x_M), \theta(x_M)) & \cdots & \phi_P(r(x_M), \theta(x_M))
    \end{bmatrix}.
\]


\section{Numerical approach for the Helmholtz Equation}
For the Helmholtz equation, the \ac{MFS} convergence and stability results resemble the previous ones for the Laplace equation with Dirichlet boundary conditions. Once again, the results are stated for identical geometries as before, where \(\Omega\) is the unit disk and the radius of \(\hat{\Omega}\) is \(R>1\). Here it is assumed that the boundary data \(g\) can be analytically extended to the annulus \(\{z \in \mathbb{C}: \frac{1}{\rho}< \abs{z} < \rho\}\), where \(\rho > 1\). The following result is due to \cite{barnett2008stability}.
\begin{theorem}
    Let \(R > 1\) and \(N\) be an even number. Then the minimum boundary error achieved by the \ac{MFS} in the unit disk satisfies
    \[
        \norm{g - \tilde{u}_{|\Gamma}}_{L^2(\Gamma)} \leq
        \begin{cases}
            C \rho^{-\frac{N}{2}}, \text{ if } \rho < R^2\\
            C \sqrt{N} R^{-N}, \text{ if } \rho = R^2\\
            C R^{-N}, \text{ if } \rho > R^2\\
        \end{cases}
    \]
    where \(C\) is a constant that not depends on \(N\).
\end{theorem}
To solve the Helmholtz equation with the \ac{MFS}, one must start by computing the eigenvalues \(\lambda\) (or the eigenfrequencies \(k\), with \(\lambda = k^2\)) first. In order to achieve that, recall that the \ac{BVP} for the Helmholtz equation
\begin{equation}\label{helm_dirichlet}
    \begin{cases}
        -\Delta u = k^2 u, \text{ in } \Omega\\
        u = 0, \text{ on } \partial \Omega
    \end{cases}
\end{equation}
is well-posed when \(k\) is not an eigenfrequency of \(\Omega\), and in that case the nullspace of the single layer potential operator
\[
    S_k \varphi(y) = \int_{\hat{\Gamma}} \Phi_k(x-y)\varphi(x) d\sigma(x)
\]
is trivial. More precisely, one can prove the following result, e.g. \cite{alves2005method}.
\begin{theorem}\label{MFS_helm_null_kern}
    If \(k\) is not an eigenfrequency of the interior Dirichlet problem, then \(\dim \left(\ker(S_k)\right)=0\).
\end{theorem}
\begin{proof}
    If \(k\) is not an eigenfrequency of \(\Omega\), then the interior problem is well posed which implies that \(S_k\varphi(x) = 0, \, \forall x \in \overline{\Omega}\) since \(S_k\varphi(x) = 0\) on \(\partial\Omega\). By analytical continuation, \(S_k\varphi(x) = 0, \; x \in \hat{\Omega}\). Since the single layer potential is continuous, then \(S_k\varphi(x) = 0, \; x \in \hat{\Gamma}\). By the well-posedness of the exterior problem (notice that the single layer potential satisfies the Sommerfeld radiation conditions), then \(S_k\varphi(x) = 0, \; \forall x \in \mathbb{R}^2\) and therefore \(\varphi(x) = 0, \, \forall x \in \Gamma\), by the jump relations in Proposition \ref{sl_jump}.
\end{proof}

Theorem \ref{MFS_helm_null_kern} can be used to search for the eigenvalues/eigenfrequencies of the Laplace operator. By virtue of the discretization of the single layer potential \eqref{MFS_approx_disc}, one should find the values \(k\) such that the nullspace of the matrix \(A(k) = \begin{bmatrix}
    \Phi_k(x_i - y_j)
\end{bmatrix}_{M \times N}\) is not trivial. Like it was discussed in the previous section \ref{n_a_MFS_lap}, that can be done in two different ways:
\begin{enumerate}
    \item if \(A(k)\) is a square matrix (with \(M=N\)), one can compute the determinant of \(A(k)\). Since the components of \(A(k)\) are complex numbers, then its determinant is also a complex number, and we consider its absolute value. In any case, instead of working with \(\abs{\determinant A(k)}\), since this value is very small, one must work with its logarithm and consider the function \(d(k) = \log \abs{\determinant A(k)}\);
    \item if \(A(k)\) is an \(M\times N\) rectangular matrix, with \(M > N\), one considers the smallest singular value, which we denote by \(\sigma_N(k)\), where the singular values of \(A(k)\) are assumed to be in decreasing order \(\sigma_1(k) \geq \dots \geq \sigma_N(k)\). We emphasize that we only work with this case in the context of the Subspace Angle Technique presented in Appendix \ref{chapter:appendixB}.
\end{enumerate}

To determine the eigenvalues/eigenfrequencies of the Laplace operator, it is necessary to locate the zeros of the functions \(d(k)\) or \(\sigma_N(k)\) in the first and second cases mentioned, respectively. This involves identifying the local minima of the functions \(d(k)\) or \(\sigma_N(k)\), which are expected to converge toward zero in highly regular domains.

To search for these roots, a simple direct search algorithm was developed to bracket the set of local minima in a given interval. The iterative algorithm used is based on the Golden Ratio Search already used in \cite{alves2005method}. First, consider the graph of \(\sigma_N(k)\) in a given interval \(I=(a, b)\) (which likely has more than one local minima) and fix (a relatively large) step size \(h\). Let \(I_{M_0}^0 = \{a_0^0, \dots, a_{M_0}^0\}\) be the discretization of \(I_{M_0}^0\) in \({M_0}\) points spaced by \(h\) in the zeroth iteration, and denote the set of local minimums of \(I_{M_0}\) by \(X^0_K = \{x_0^0, \dots, x_K^0\} \subset I_{M_0}\), i.e., \(\forall i = 1,\dots, K\) there exists \(c^0, d^0 \in I_{M_0}^0\) such that \(c^0 = x_i^0 - h\), \(d^0 = x_i^0 + h\) and \(x_i < \min(c^0, d^0) \). Then, for each \(x_i^0\), \(I_{M_0}^0\) is enlarged with the middle points between \(c^0\) and \(x_i^0\), \(d^0\) and \(x_i^0\), and it is denoted by \(\tilde{I}_{M_1}^1\) (notice that \(M_0 < M_1\))\footnote{Given the nature of the algorithm, one can also consider the left adjacent point to \(c^0\), which we denote by \(e_0 \in I^0_{M_0}\), compute and add their middle point to \(\tilde{I}_{M_1}^1\)}. Finally, we sort \(\tilde{I}_{M_1}^1\) in increasing order and repeat the process for a specified depth \(d\). When the maximum depth is attained, one was able to successfully find small intervals which bracket \textit{each local minimum} of \(\sigma_N\) in \(I\), and it is now possible to apply a direct search method to find it to any desired precision: in this work, Brent's method was used \cite{brent1971algorithm}, although Golden Ratio Search is also possible. The general form of the algorithm is given in \ref{direct_bracketing_algorithm}.

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    Set maximum depth \(d\)\;
    Set step size \(h\)\;
    Set bracketing interval \(I=(a, b)\)\;
    \Begin{
    Discretize \(I\) into \(I_{M_0}^0 = \{a_0^0,\dots,a_{M_0}^0\}\), where \(a_{j+1} = a_j + h\) for each \(j = 1,\dots M_0-1\)\;
    Set \(s=0\)\;
    \BlankLine
    \CommentSty{(Bracketing step)}\;
    \While{\(s < d\)}{
        Compute \(X^s_{K_s} = \{x_0^s, \dots, x_{K_s}^s\}\), the set of local minima of \(I_{M_s}^s\)\;
        Let \(E\) be an empty array\;
        \ForEach{\(x \in X^s_{K_s}\)}{
            Consider the adjacent points to \(x\) given by \(c, d \in I^s_{M_s}\) such that \(c < x <d\)\;
            Consider the left adjacent point to \(c\), denoted by \(e\)\;
            Compute \(\tilde{c} = \frac{c+x}{2}\)\;
            Compute \(\tilde{d} = \frac{d+x}{2}\)\;
            Compute \(\tilde{e} = \frac{e+c}{2}\)\;
            Append \(\tilde{c}\), \(\tilde{d}\) and \(\tilde{e}\) to \(E\)\;
            }
        Let \(\tilde{I}^{s+1}_{M_{s+1}} = I^s_{M_s} \cup E\)\;
        Define \(I^{s+1}_{M_{s+1}} = sort(\tilde{I}^{s+1}_{M_{s+1}})\)\;
        \(s \leftarrow s+1\)\;
        }
        \BlankLine
        \CommentSty{(Direct search step)}\;
        Let E be an empty array\;
        \ForEach{\(x \in X^d_{K_d}\)}{
            Consider the adjacent points to \(x\) given by \(c, d \in I^d_{M_d}\) such that \(c < x <d\)\;
            \(\lambda = Brent(c, d)\)\;
            Append \(\lambda\) to E\;
        }
        \Return{E}
    }
    \caption{Direct Bracketing Algorithm}
    \label{direct_bracketing_algorithm}
\end{algorithm}

\begin{remark}
    Although the algorithm \ref{direct_bracketing_algorithm} is enough, we point out some problems and possible changes to consider. First, there are no guarantees regarding the eigenvalues found: this depends on the chosen interval and the step. For example, if the first eigenvalue is not in the chosen interval, it will never be found. One may also find a ``jump'' if two eigenvalues are arbitrarily close, but the algorithm just found one of them: this is the case when an eigenvalue has a multiplicity bigger than one, which depends on the domain. However, this last case is easy to rule out if one considers the one parameter transformation between the domain \(\Omega\) and the unitary disk \(\mathbb{D}\) given by
    \[
        \Omega(t) = (1-t)\mathbb{D} + t \Omega, \, t \in (0, 1),
    \]
    since the graph of the eigenvalues is continuous concerning \(t\). Regarding the complexity of the algorithm, the objective is to find the minima of the function \(\sigma_N(k)\) in the \textit{least} amount of evaluations: a brute-force approach with a very small step is not feasible since each evaluation takes some time for big complex-valued matrices. However, we note that the algorithm can be improved by just considering the initial point \(a\) and ``walking forward'' with step size \(h\). In that case, one could bracket each local minimum individually and only break to the main loop when the maximum depth was reached for each local minimum initially found. The loop would \texttt{break} when the number of eigenvalues found attains a prescribed value.
\end{remark}

Finally, a posteriori estimate based on a result proved by Moler and Payne in \cite{moler1968bounds} is stated.
\begin{theorem}
    Let \(\tilde{k}\) and \(\tilde{u} \in C^2(\Omega) \cap C(\overline{\Omega})\) be an approximate eigenfrequency and eigenfunction which satisfy the following problem:
    \[
    \begin{cases}
        -\Delta \tilde{u} = \tilde{k}^2 u, &\text{ in } \Omega\\
        u = \xi(x), &\text{ on } \Gamma.
    \end{cases}
    \]
    Then, there exists an eigenfrequency \(k_n\) of \eqref{helm_dirichlet} such that
    \[
        \frac{\abs{{k_n} - {\tilde{k}}}}{\abs{k_n}} \leq \theta
    \]
    where
    \[
        \theta = \frac{\sqrt{\abs{\Omega}} \norm*{\xi}_{L^\infty (\Gamma)}}{\norm{\tilde{u}}_{L^2(\Omega)}}.
    \]
    If, in addition, \(\tilde{u}\) and \(u\) is the normalized orthogonal projection of \(\tilde{u}\) onto the eigenspace of \(k_n\), then
    \[
        \norm{\tilde{u} - u}_{L^2(\Omega)} \leq \frac{\theta}{\rho_n}\left(1+\frac{\theta^2}{\rho_n^2}\right)^\frac{1}{2},
    \]
    where
    \[
        \rho_n = \min_{k_n \neq k_p} \frac{\abs{k^2_p - \tilde{k}^2}}{k^2_p}, \text{ for } p \in \mathbb{N}.
    \]
\end{theorem}

% \subsection{The Subspace Angle Technique}

% As stated before, one of the drawbacks of this method is the ill-conditioning of the system. In this subsection we introduce the so-called \textit{Subspace Angle Technique}, first presented in \cite{betcke2005reviving}. Intuitively, there are two problems at play: firstly, while the \ac{MFS} only needs the boundary data to approximate the solution of the \ac{BVP}, the exponential growth of the condition number against the exponential convergence can be seen has the lack of information given by the collocation points on the boundary, which is not enough to decide if an approximate eigenfunction is spurious; secondly, while we proved the linear independence of the basis functions, in practice the columns of the matrix \(A(k)\) are almost linear dependent if its number is too large (in fact, this is, once again, associated with the distance from the boundary to the artificial boundary).

% To solve the first problem, we add additional interior points in order to over-determine the system; and for the second problem, we construct an orthonormal basis of the column space of \(A(k)\), denoted by \(\mathcal{C}(A(k))\), using the \(QR\) factorization of \(A(k)\). Let \(M_B\) be the number of boundary points and \(M_I\) the number of interior points, such that \(M=M_B+M_I\). Then, by adding some interior points the matrix \(A(k)\) can be extended to
% \[
%     A(k) = \begin{bmatrix}
%         A_B(k)\\
%         A_I(k)
%     \end{bmatrix},
% \]
% where the indices \(B\) and \(I\) correspond to the block matrices with the boundary and interior collocation points, respectively. To generate an orthonormal basis of the column space of \(A(k)\), consider the \(QR\) factorization of \(A(k)\), given by \(A(k)=Q(k)R\), where \(Q(k)\) is a unitary complex matrix (i.e., \(Q^\dagger(k) = Q^{-1}(k)\)) and \(R\) is an upper triangular matrix. By partitioning \(Q(k)\) in the boundary and interior collocation points, we also have
% \begin{equation*}
%     Q(k) = \begin{bmatrix}
%         Q_B(k)\\
%         Q_I(k)
%     \end{bmatrix},
% \end{equation*}
% and each unit vector \(u \in \mathcal{C}(A(k))\) has the form
% \begin{equation}\label{sat_qr}
%     u = \begin{bmatrix}
%         u_B\\
%         u_I
%     \end{bmatrix} = Q(k)v = \begin{bmatrix}
%         Q_B(k)\\
%         Q_I(k)
%     \end{bmatrix}v
% \end{equation}
% for some \(v \in \mathbb{R}^2\), \(\norm*{v} = 1\). Assuming homogeneous Dirichlet boundary conditions, we are interested in non-trivial solutions \(v \in \mathbb{R}^2\) to the above problem when \(u \approx 0\) at the boundary, i.e., to solve the constrained minimization problem
% \[
%     \min_{v \in \mathbb{R}^2, \norm*{v}=1} \norm*{Q_B(k) v}.
% \]
% The above problem is easy to solve and has a closed-form solution which can be found using Lagrange multipliers. The solution \(\check{v}\) is the right singular vector associated with the smallest singular value \(\sigma_N\) and
% \[
%     \sigma_N(k) = \norm*{Q_B(k) \check{v}}.
% \]
% Let \(\check{u} = Q(k) \check{v}\). Taking the norm on both sides of equation \eqref{sat_qr}, one can write
% \begin{equation}\label{sat_eq}
%     1 = \norm{\check{u}}^2 = \norm{\begin{bmatrix}
%         Q_B(k)\\
%         Q_I(k)
%     \end{bmatrix}\check{v}}^2 = \sigma_N^2(k) + \norm*{Q_I(k) \check{v}}^2.
% \end{equation}
% Notice how equation \eqref{sat_eq} can be used to eliminate spurious solutions: since \(0 < \sigma_N < 1\), if \(\sigma_N \approx 1\), then \(Q_I(k) \check{v} \approx 0 \implies u_I \approx 0\) which is an incorrect solution (is zero on the interior and does not satisfy the boundary constraints); on the other hand, if \(\sigma_N \approx 0\), then we found an eigenfunction which is small on the boundary points and whose interior is not null.

% The name Subspace Angle Technique comes from the fact that \(\sigma_N\) is related to the angle between the subspaces \(\mathcal{C}(A(k))\) and \(\mathcal{G}_0\), the space of vectors that are zero at boundary points\footnote{\(\mathcal{G}_0\) can be seen as the discretization of the functions which satisfy the boundary conditions but not the Helmholtz equation.}. The angle \(\phi(k)=\angle (\mathcal{C}(A(k)), \mathcal{G}_0)\) between both subspaces is defined by
% \[
%     \cos \phi(k) = \sup_{\substack{u \in \mathcal{C}(A(k)), \, \norm{u}=1 \\ v \in \mathcal{G}_0, \, \norm*{v} = 1}} (u, v),
% \]
% and one can prove (c.f. \cite{betcke2005reviving}) that
% \[
%     \sigma_N = \sin \phi(k).
% \]
% Therefore, the discrete problem has a non-trivial solution (i.e., \(\lambda\) is an eigenvalue of the Laplace operator) if and only if \(\mathcal{C}(A(k))\) and \(\mathcal{G}_0\) have a non-trivial intersection (i.e., \(\phi(k) = l \pi, \, l \in \mathbb{Z}\)).

% \begin{remark}
%     While the construction above assumed homogeneous Dirichlet boundary conditions, it can be easily generalized to any type of homogeneous boundary conditions \(\mathcal{B}\) by considering the appropriate \(A\) matrix.
% \end{remark}

% \begin{remark}
%     Neither the enrichment technique nor the Subspace Angle Technique are specific methods only applicable to the Laplace equation and the Helmholtz equation, respectively. They can be used for both equations at the same time. For example, in \cite{antunes2010meshfree}, both methods were used to study the spectrum of the Laplace operator in domains with corners and cracks.
% \end{remark}
