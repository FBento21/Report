% #############################################################################
% This is Chapter 2
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{From Spectral Theory and Shape Optimization to the Poisson Transmission Problem}
% \cleardoublepage
% The following line allows to ref this chapter
\label{chap:back}

% #############################################################################
Until otherwise indicated, let \(\Omega \subset \mathbb{R}^d\) be an open and bounded domain with \(C^2\) boundary, with $d \geq 2$.

Let \(p(x)\) be a polynomial in the variables \(x=(x_1,\dots,x_d)\), and \(p(\partial)\) be the partial differential operator obtained by substituting \(\frac{\partial}{\partial x_i}\) for \(x_i\) in \(p(x)\). We start by introducing the definition of a fundamental solution of a partial differential operator:

\begin{definition}
    Consider the polynomial \(p(\partial)\). A distribution \(\Phi \in \mathcal{D}^\star(\mathbb{R}^n)\) is said to be the fundamental solution of the partial differential operator \(p(\partial)\) if
    \[
        p(\partial) \Phi = \delta,
    \]
    where \(\delta\) is the Dirac Delta distribution.
\end{definition}

In particular, given \(\Phi\) satisfying the above conditions, we have that \(p(\partial)\Phi(x) = 0\) for \(x \in \mathbb{R}^d\setminus \{0\}\). Then, it is easy to see that the fundamental solution of a partial differential operator is not unique: if \(\Phi\) is such that \(p(\partial) \Phi = \delta\) and \(p(\partial) v(x) = 0\) for all \(x \in \mathbb{R}^d\), then \(p(\partial) (\Phi + v) = \delta\). However, the fundamental solutions given below are chosen because they exhibit an important radial behavior, which is needed for the numerical method presented in Chapter 4.

An important result in this context is Malgrange-Ehrenpreis theorem.

\begin{theorem}[Malgrange-Ehrenpreis]\label{malgrange-ehrenpreis}
    Every constant partial differential operator $p(\partial)$, has a fundamental solution $\Phi \in \mathcal{D}^\star(\mathbb{R}^d)$.
\end{theorem}
\begin{proof}
    See \cite{reed1975ii}.
\end{proof}
Below we present the fundamental solution of Laplace differential operator and some major results concerning Laplace and Helmholtz equations. 

\section{The Laplace Operator}
\label{section:laplace_op}

In what follows, we present some results of the Laplace operator associated with the well-known Laplace equation
\begin{equation} \label{laplace_equation}
    -\Delta u = 0.
\end{equation}
Throughout this first part we are mostly concerned about its spectrum which is associated with the Helmholtz equation
\begin{equation} \label{helmholtz_equation}
    -(\Delta+\lambda) u = 0 \iff -\Delta u = \lambda u.
\end{equation}
% when subject to Dirichlet, Neumann or Robin boundary conditions.

\begin{remark}
    In some literature, it is common to write the Helmholtz equation as \(-\Delta u = k^2 u\), where \(k\) is known as an eigenfrequency, and \(k^2 = \lambda\). This terminology is a consequence of the fact that the Helmholtz equation can be derived from the wave equation, where a constant \(c^2\) (where \(c \in \mathbb{R}\)) is used.
\end{remark}

By Theorem \ref{malgrange-ehrenpreis} we know that both equations \eqref{laplace_equation} and \eqref{helmholtz_equation} admit a fundamental solution that are given below.

\begin{proposition}
    The function \(\Phi: \mathbb{R}^d \setminus \{0\} \rightarrow \mathbb{R}\) given by
    \[
    \Phi(x) = \begin{cases}
        -\frac{1}{2 \pi} \log \abs*{x}, & d=2\\
        \frac{1}{(n-2)\abs{\partial B_1}}\frac{1}{\abs*{x}^{d-2}}, & d > 2
    \end{cases}    
    \]
    is the fundamental solution of equation \eqref{laplace_equation}, where \(\abs{\partial B_1}\) denotes the boundary measure of the unitary ball.
\end{proposition}
\begin{proposition}\label{helm_fund_sol}
    The function \(\Phi_\lambda: \mathbb{R}^d \setminus \{0\} \rightarrow \mathbb{R}\) given by
    \[
    \Phi_\lambda(x) = \begin{cases}
        \frac{i}{4} H_0^{(1)}(\sqrt{\lambda} \norm*{x}), & d=2\\
        \frac{e^{i \sqrt{\lambda} \norm*{x}}}{4 \pi \norm*{x}}, & d > 2
    \end{cases}    
    \]
    is the fundamental solution of equation \eqref{helmholtz_equation}, where \(H_0^{(1)}\) is the Hankel function of first kind and order 0, given by
    \[
        H_0^{(1)}(x) = J_0(x) + i Y_0(x),
    \]
    where \(J_0\) and \(Y_0\) are the Bessel functions of first and second kind with order zero, respectively.
\end{proposition}

If one considers the eigenfrequency form of the Helmholtz equation, then the fundamental solution in Proposition \eqref{helm_fund_sol} would change accordingly.

\subsection{Some shape optimization results}

In this subsection some important results regarding shape optimization are presented. More precisely, we are interested in problems of the form
\begin{equation}\label{shape_prob}
    \min\{F(\lambda_1(\Omega),\dots, \lambda_k(\Omega)): \abs{\Omega} = c, \Omega \subset \mathbb{R}^d\},
\end{equation}
where \(F\) is a function of the first \(k\) eigenvalues of the Helmholtz equation \eqref{helmholtz_equation} and \(c > 0\). We point the reader to \cite{henrot2006extremum} and \cite{henrot2017shape} to more details.

\begin{theorem}[Faber-Krahn inequality]\label{faber-krahn}
    Let \(B\) be a ball of volume \(c\). Then, among all domains \(\Omega\) of volume \(c\) we have that,
    \[
    \lambda_1(B) = \min\{\lambda_1(\Omega): \abs{\Omega} = c\}.
    \]
    In particular, as proved by Krahn in \cite{krahn1926minimaleigenschaften}, the corresponding isoperimetric inequality
    \[
        \lambda_1(\Omega) \geq \left(\frac{C_d}{c}\right)^\frac{d}{2}j_{d/2-1, 1},
    \]
    where \(C_d\) is the volume of the \(d\)-dimensional unit ball and \(j_{p,1}\) is the first positive zero of the Bessel function \(J_p\), holds.
\end{theorem}

Theorem \eqref{faber-krahn} is a classic form of an isoperimetric inequality, conjectured for the first time by Lord Rayleigh. More recently, a reverse of the Faber-Krahn inequality was proven in \cite{freitas2008sharp}.
\begin{theorem}\label{reverse_faber-krahn}
    Let \(\Omega\) be a bounded convex domain of \(\mathbb{R}^d\) and denote the inradius of \(\Omega\) (radius of the largest ball contained within the domain) by \(\rho_\Omega\). Then,
    \[
    \lambda_1(\Omega) \leq \frac{\abs{\partial \Omega}}{d \rho_\Omega \abs{\Omega}} \lambda_1(\mathbb{D})
    \]
\end{theorem}   

While Faber-Krahn inequality deals with the first eigenvalue of the Laplace operator, other results have been uncovered for the second and third eigenvalues:

\begin{theorem}[Krahn-Szeg\H{o}]\label{krahn_szego}
    The domain that minimizes the quantity
    \[
    \min\{\lambda_2(\Omega): \abs{\Omega} = c\}
    \]
    consists of two equal and disjoint balls of volume \(\frac{c}{2}\).
\end{theorem}

A result regarding the topology of a given domain \(\Omega\) and its connection with the minimization of each eigenvalue \(\lambda_k\) was given by Wolf and Keller in \cite{wolf1994range}. Roughly speaking, the result states that if a minimizer of \(\lambda_k\) is not connected, then each connected component must be a minimizer for a lower eigenvalue.
\begin{theorem}[Wolf-Keller]\label{wolf_keller}
    Let \(\Omega_k^\star\) be the union of two disjoint domains, each of them with positive volume. Then,
    \[
        \lambda_k^\star = (\lambda_i^\star)^\frac{d}{2} + (\lambda_{k-i}^\star)^\frac{d}{2} = \min_{1 \leq j \leq \frac{k-1}{2}}((\lambda_j^\star)^\frac{d}{2} + (\lambda_{k-j}^\star)^\frac{d}{2}),
    \]
    where \(i\) is a value of \(j \leq \frac{k-1}{2}\) that minimizes \(\lambda_i^\star + \lambda_{k-i}^\star\). Furthermore,
    \[
        \Omega_k^\star = \left[\left(\frac{\lambda_i^\star}{\lambda_k^\star}\right)^\frac{1}{2} \Omega_i^\star \bigcup \left(\frac{\lambda_{k-i}^\star}{\lambda_k^\star}\right)^\frac{1}{2} \Omega_{k-i}^\star \right]
    \]
\end{theorem}

The generalization of the Theorems \eqref{faber-krahn} and \eqref{krahn_szego} becomes harder to prove for high order eigenvalues. Bucur and Henrot proved in \cite{henrot2000minimization} that there exists a domain \(\Omega\) that minimizes \(\lambda_3\), and it is conjectured to be the disk\footnote{Notice that \(\Omega_3\) must be connected in dimension \(2\). Otherwise, by Theorem \eqref{wolf_keller}, \(\Omega_3\) would be the union of the domains that minimize \(\lambda_1\) and \(\lambda_2\) (see Theorems \eqref{faber-krahn} and \eqref{krahn_szego}), where one can explicitly compute \(\lambda_3 = \lambda_1 + \lambda_2 \approx 51.504\). However, this would be a contradiction since the eigenvalue of the unit disk is \(\lambda_3(\mathbb{D}) \approx 46.125\), when considering unitary measure \(c=1\). For three dimensions the result is the same, but for \(d \geq 4\) one cannot conclude anything.}.
% \begin{theorem}[Bucur-Henrot]
%     There exists a domain \(\Omega\) that minimizes the quantity
%     \[
%     \min\{\lambda_3(\Omega): \abs{\Omega} = c\}.
%     \]
% \end{theorem}
In \cite{bucur2012minimization}, Bucur was able to assert the existence of, at least, one solution to problem \eqref{shape_prob}.
\begin{theorem}[Bucur]
    For every \(k \in \mathbb{N}\) problem
    \[
    \min\{\lambda_k(\Omega): \abs{\Omega} = c\}
    \]
    has at least one solution. Moreover, every solution is bounded and has finite perimeter.
\end{theorem}

In \cite{mazzoleni2013existence}, Mazzoleni and Pratelli were able to generalize the above results for (\textit{quasi}-)open sets and for a general functional \(F\) considered in \eqref{shape_prob} (see the reference for more details and definition of a quasi-open set).
\begin{theorem}[Mazzoleni-Pratelli]
    Let \(k \in \mathbb{N}\) and suppose that \(F:\mathbb{R}^k \rightarrow \mathbb{R}\) in \eqref{shape_prob} is lower semicontinuous, increasing in each variable. Then, among the quasi-open sets, there exists a bounded minimizer \(\Omega\) for the problem \eqref{shape_prob}. More precisely, a minimizer \(\Omega\) is contained in a cube of side \(R\), where \(R\) depends on \(k\) and on the dimension of the space \(d\), but not on \(F\).
\end{theorem}

In this work, we are also interested in studying the eigenvalues of polygonal domains, such as triangles and quadrilaterals. An important result concerning these domains is the fact that they are invariant under the so-called \textit{Steiner symmetrization} (in the sense that the Steiner symmetrization of a triangle or a quadrilateral is still a triangle or a quadrilateral, respectively), which preserves their area while decreasing the perimeter and its first eigenvalue. This type of transformation enables us to state the following result:

\begin{theorem}[Pólya-Szég\H{o}]
    The quantity \(\lambda_1\) is minimized for equilateral triangles among all triangles, where the inequality
    \[
    \frac{4 \pi^2}{\sqrt{3}} \leq  \lambda_1(T)
    \]
    holds for every triangle \(T\) of area \(1\).
    Analogously, \(\lambda_1\) is minimized for the square among all quadrilaterals.
\end{theorem}

However, an analogous result for the \(n\)-side polygon is still an open problem conjectured by Pólya and Szég\H{o} in \cite{polya1951isoperimetric}.
\begin{conjecture}\label{polya_szego_conjecture}
    Let \(n \geq 5\) and consider the class of \(n\)-side polygons. Then, the regular \(n\)-side polygon has the least first eigenvalue among all \(n\)-side polygons with fixed area.
\end{conjecture}

Very recently, Bogosel and Bucur proved in \cite{bogosel2022polygonal} that Conjecture \eqref{polya_szego_conjecture} can be reduced to a finite number of certified numerical computations with machine precision, and performed them for \(k=5, 6, 7, 8\).

Related to triangles, we can also cite the recent work of Serrano and Orriols in \cite{gomez2021any}, which was based on the previous work of Antunes and Freitas \cite{antunes2011inverse} who conjectured that the first three eigenvalues are enough to define the shape of a triangle (such result resembles the famous Marc Kac question if one can "hear the shape of a drum" in \cite{kac1966can}, that is, if given the frequencies produced by a drum one could identify the drum's shape, which has proven to be false, see \cite{gordon1992isospectral} for more details). In any case, Serano and Orriols were able to show that not any three eigenvalues suffice to fully characterize the shape of a triangle.
\begin{theorem}[Serrano-Orriols]
    There exist two triangles \(T_A\) and \(T_B\) not isometric to each other such that \(\lambda_i(T_A) = \lambda_i(T_B)\), for \(i=1, 2, 4\).    
\end{theorem}

Other important results in this area are related with the ratio and the gap between the first and the second eigenvalues.
\begin{theorem}[Ashbaugh-Benguria]
    The solution of the maximization problem
    \[
    \max \Big\{\frac{\lambda_2(\Omega)}{\lambda_1(\Omega)}: \Omega \subset \mathbb{R}^d, \Omega \text{ open} \Big\}
    \]
    is the ball. In particular, it can be shown that
    \[
    \frac{\lambda_2(\Omega)}{\lambda_1(\Omega)}  \leq \frac{j_{\frac{d}{2},1}^2}{j_{\frac{d}{2}-1,1}^2}.
    \]
\end{theorem}

\begin{remark}
    Note that in theorem above we do not make any constraint regarding the volume of our domain (except finite measure). This as consequence of the homogeneity proven in Corollary \eqref{lap_homo} and the fact that we are now considering a ratio between two eigenvalues in the same domain.
\end{remark}


% #############################################################################
\section{The Dirac Operator}
 
Motivated by recent advancements in nuclear, molecular physics and the discovery of very interesting electrical, mechanical and thermal properties, Dirac materials have resurged a lot of attention in the Dirac equation. Presented by Paul Dirac in its 1928 article \cite{dirac1928quantum}, Dirac equation was able to successfully merge the famous Schr\"{o}dinger equation with special relativity, while explaining the weird phenomena that today is known as \textit{spin}, while predicting the existence \textit{antimatter}.
Capable of describe the relativistic dynamics of spin-$\frac{1}{2}$ particles (like the electron), one can determine the energy states by studying the spectrum of the Hamiltonian (Dirac) operator \(\hat{H}\) in \(L^2(\Omega, \mathbb{C}^2)\) for \(\Omega \subset \mathbb{R}^2\),
\begin{equation}\label{dirac_eq}
    \hat{H} u = E u \quad \text{with} \quad \hat{H}=c \, \mathbf{a} \cdot \mathbf{p} + m c^2 \mathbf{\beta} + V(x)\mathbb{I}_4,
\end{equation}
where \(\mathbf{p} = -i \nabla\) is the momentum operator, \(c\) is the speed of light, \(m\) is the electron mass, \(E\) is the electron energy, \(V(x)\) is the vector potential and \(u \in L^2(\Omega, \mathbb{C}^2)\) is a four-spinor\footnote{In what follows, we will be using natural units, where \(c=1\).}. One of the major problems regarding the study of Dirac's equation is the fact that, unlike Schr\"{o}dinger's equation, it has a matrix structure that is given by the Pauli matrices
\[
\sigma_x = \begin{bmatrix}
    0 & 1\\
    1 & 0
\end{bmatrix} \qquad \sigma_y = \begin{bmatrix}
    0 & -i\\
    i & 0
\end{bmatrix} \qquad
\sigma_z = \begin{bmatrix}
    1 & 0\\
    0 & -1
\end{bmatrix}
\]
which can be incorporated in the \(4 \times 4\) matrices \(\mathbf{a}\) and \(\mathbf{\beta}\):
\[
a_i = \begin{bmatrix}
    0 & \sigma_i\\
    \sigma_i & 0
\end{bmatrix} \qquad
\beta = \begin{bmatrix}
    \mathbb{I}_2 & 0\\
    0 & -\mathbb{I}_2
\end{bmatrix}.
\]

Setting the potential \(V(x)=0\) and considering \(\Omega \subset \mathbb{R}^2\) be a bounded and open domain with \(C^3\) boundary, we can rewrite equation \eqref{dirac_eq} in the form    
\begin{equation}\label{dirac}
    \begin{bmatrix}
        m & -i(\partial_1 - i \partial_2)\\
        -i(\partial_1 + i \partial_2) & -m
    \end{bmatrix}
    \begin{bmatrix}
        u_1(x)\\
        u_2(x)
    \end{bmatrix}
    =E
    \begin{bmatrix}
    u_1(x)\\
    u_2(x)
    \end{bmatrix}
\end{equation}
where we let \(\mathbf{u}(x)=\begin{bmatrix}
    u_1(x)\\
    u_2(x)
    \end{bmatrix}\).
In particular, we are interested in studying it under the so-called \textit{infinite-mass boundary conditions}. For a point \(x \in \Gamma = \partial\Omega\), we denote by \(\mathbf{n}(x) = \begin{pmatrix}
    n_1(x), n_2(x)
\end{pmatrix}^T\) the outward unit vector to \(\Omega\), and define the operator domain
\[
D(\hat{H}) = \{u \in H^1(\Omega, \mathbb{C}^2): u_2 = i(n_1+i n_2)u_1 \text{ on } \Gamma\}.
\]

Let \(\mathbf{\tau}(x) = \begin{pmatrix}
    n_2(x), -n_1(x)
\end{pmatrix}^T\) be the unit tangent vector to some point \(x \in \Gamma\) such that \((\mathbf{\tau}(x), \mathbf{n}(x))\) is a positively-oriented orthonormal basis of \(\mathbb{R}^2\). Considering the arc-length parametrization of \(\Gamma\) given by the map
\[
s: [0, L) \rightarrow \mathbb{R}^2, \quad s(t) = \int_0^t \norm{r'(\sigma)} d\sigma
\]
where \(L\) represents the arc-length of \(\Gamma\) and \(r\) is a parametrization of \(\Gamma\), we denote by \(\kappa:\Gamma \rightarrow \mathbb{R}\) the signed curvature of \(\Gamma\) where the \textit{Frenet-Serret} formula (we dropped the dependency of \(s\) in the parameter \(t\))
\[
    \frac{\partial\mathbf{\tau}}{\partial s}=\kappa(s)\mathbf{n}(s)
\]
holds. Similar to the Theorem \eqref{spec_lap_pre}, some general results regarding the spectrum of the Dirac operator can also be stated.

\begin{proposition}
    Consider the eigenvalue problem stated in \eqref{dirac}. Then, the following results hold, \footnote{Notice that we changed the eigenvalue notation \(E\) to \(\lambda\). Not only for coherence reasons, but also because we are mainly interested in the mathematical description of the problem, and not in the physical intuition behind it (the energy of a spin-\(\frac{1}{2}\) particle).}
    \begin{itemize}
        \item The eigenvalues are real and the spectrum of the Dirac operator is discrete. Also, the spectrum is symmetric with respect to zero and the eigenvalues can be arranged as follows
        \[
        -\infty \leftarrow \dots \leq -\lambda_3 \leq -\lambda_2 \leq -\lambda_1 < 0 < \lambda_1 \leq \lambda_2 \leq \lambda_3 \leq \dots \rightarrow \infty;
        \]
        \item The principal (first) eigenvalue can be described using the variational form
        \[
        \lambda_1^2 = \min_{0 \neq u \in D(\hat{H})}\frac{\norm*{\nabla u}_{L^2(\Omega)}^2 + m^2 \norm{u}_{L^2(\Omega)}^2 + m \norm{\gamma_0 u}_{L^2(\partial\Omega)}^2}{\norm{u}_{L^2(\Omega)}^2},
        \]
        where \(\gamma_0: H^1(\Omega, \mathbb{C}^2) \rightarrow L^2(\Gamma, \mathbb{C}^2)\) denotes the trace of \(u\);
        \item Let \(m=0\) and \(\Omega\) to be the unit disk \(\mathbb{D}\).Then, we have that the first eigenvalue is the solution to the equation
        \[
        J_0(\lambda) = J_1(\lambda),
        \]
        and the associated eigenfunction is (in polar coordinates)
        \[
        u(r, \theta) = \begin{pmatrix}
            J_0(\lambda r)\\
            i e^{i \theta}J_1(\lambda r)
        \end{pmatrix}.    
        \]
        For future comparison, its numerical approximation is \(\lambda \approx 1.434696\), where we recall that \(J_p\) is the Bessel function of first kind of order \(p\).
    \end{itemize}
\end{proposition}

The following proposition regarding the lack of separable solutions of the Dirac operator will have important consequences in the numerical approach to solve Dirac equation. However, we start by stating and proving the following auxiliary lemma:

\begin{lemma}\label{lemma_sep_norm}
    Let \(u \in H^2(\Omega)\) a solution of \eqref{dirac} and \(u \in D(\hat{H})\). Then we have
    \begin{equation}\label{sep_norm}
        \norm*{\hat{H}u}_{L^2(\Omega)}^2 = \norm*{\nabla u }_{L^2(\Omega)}^2 + m^2 \norm*{u}_{L^2(\Omega)}^2 + m \norm*{\gamma u}_{L^2(\partial\Omega)}^2 -\frac{1}{2}\int_{\Gamma}\kappa \abs{u}^2 d\sigma
    \end{equation}
\end{lemma}
\begin{proof}
    Recalling the \(L^2(\Omega)\) inner product for complex functions
    \[
    (f, g)_{L^2(\Omega)} = \int_\Omega f \bar{g} dx,
    \]
    \eqref{sep_norm} can be rewritten as 
    \begin{align}
        \norm*{\hat{H}u}_{L^2(\Omega)}^2 &= m^2 \norm*{u_1}_{L^2(\Omega)} + m^2 \norm*{u_2}_{L^2(\Omega)} \label{sep_norm_1}\\ 
        & + i m \int_\Omega u_1(\partial_1 + i \partial_2)\bar{u}_2dx - i m \int_\Omega \bar{u}_1(\partial_1 - i \partial_2)u_2 dx \label{sep_norm_2}\\ 
        & + i m \int_\Omega \bar{u}_2(\partial_1 + i \partial_2)u_1 dx - i m \int_\Omega u_2(\partial_1 - i \partial_2)\bar{u}_1 dx \label{sep_norm_3}\\ 
        & +\norm*{(\partial_1 - i \partial_2)u_2}_{L^2(\Omega)}^2 + \norm*{(\partial_1 + i \partial_1)u_1}_{L^2(\Omega)}^2. \label{sep_norm_4}
    \end{align}
    We now address each line of the expression above individually:
    \begin{itemize}
        \item For \eqref{sep_norm_1} we directly have
                \[
                m^2 \norm*{u}_{L^2(\Omega)}.
                \]
        \item For \eqref{sep_norm_2} we integrate by parts the first part:
                \[
                \int_\Omega u_1(\partial_1 + i \partial_2)\bar{u}_2dx = \int_{\partial\Omega} u_1\bar{u}_2(1+i)d\sigma - \int_\Omega \bar{u}_2(\partial_1 + i \partial_2)u_1dx
                \]
            where the last part cancels with the first part of \eqref{sep_norm_3}.
        \item Analogously, for \eqref{sep_norm_3} we obtain a similar result for the last part
                \[
                \int_\Omega u_2(\partial_1 - i \partial_2)\bar{u}_1dx = \int_{\partial\Omega} u_2\bar{u}_1(1-i)d\sigma - \int_\Omega \bar{u}_1(\partial_1 - i \partial_2)u_2dx 
                \]
                where the last part cancels with the last part of \eqref{sep_norm_2}.
        \item For \eqref{sep_norm_4} we firstly deduced the following property:
                \[
                \Im \Big(\int_\Omega \partial_1 v \partial_2 \bar{v}dx\Big) = \frac{1}{2 i} \int_{\partial\Omega} \bar{v} \partial_\tau v d \sigma, \; \forall v \in H^2(\Omega),
                \]
                where \(\partial_\tau v= \tau \cdot \nabla v\), which can be obtained using integration by parts.
                Then, for each part we have
                \begin{align*}
                \norm*{(\partial_1 - i \partial_2)u_2}_{L^2(\Omega)}^2 &= \norm*{\nabla u_2}_{L^2(\Omega)}^2 + i \Big(\int_\Omega \partial_1 u_2 \partial_2 \bar{u}_2dx - \int_\Omega \partial_2 u_2 \partial_1 \bar{u}_2dx\Big)\\
                & = \norm*{\nabla u_2}_{L^2(\Omega)}^2 + i\int_{\partial\Omega} \bar{u}_2 \partial_\tau u_2 d \sigma
                \end{align*}
                \vspace*{-1cm}
                \begin{align*}
                \norm*{(\partial_1 + i \partial_2)u_1}_{L^2(\Omega)}^2 &= \norm*{\nabla u_1}_{L^2(\Omega)}^2 - i \Big(\int_\Omega \partial_1 u_1 \partial_2 \bar{u}_1dx - \int_\Omega \partial_2 u_1 \partial_1 \bar{u}_1dx\Big)\\
                & = \norm*{\nabla u_1}_{L^2(\Omega)}^2 - i\int_{\partial\Omega} \bar{u}_1 \partial_\tau u_1 d \sigma
                \end{align*}
                where we used the property above.
    \end{itemize}
    As such, we can write everything as
    \begin{align*}
        \norm*{\hat{H}u}_{L^2(\Omega)}^2 &= m^2 \norm*{u}_{L^2(\Omega)} + i m \Big(\int_{\partial\Omega} u_1\bar{u}_2(1+i)d\sigma - \int_{\partial\Omega} u_2\bar{u}_1(1-i)d\sigma \Big)\\
        & + \norm*{\nabla u}_{L^2(\Omega)} + i\Big( \int_{\partial\Omega} \bar{u}_2 \partial_\tau u_2 d \sigma -  \int_{\partial\Omega} \bar{u}_1 \partial_\tau u_1 d \sigma \Big).
    \end{align*}
    Finally, using the boundary conditions \(u_2 = i(n_1 + i n_2)u_1\), we conclude that
    \begin{align*}
    i m \Big(\int_{\partial\Omega} u_1\bar{u}_2(1+i)d\sigma - \int_{\partial\Omega} u_2\bar{u}_1(1-i)d\sigma \Big) = \norm*{\gamma u}_{L^2(\partial\Omega)}^2
    \end{align*}
    while
    \begin{align*}
    i\int_{\partial\Omega} \bar{u}_2 \partial_\tau u_2 d \sigma -  i\int_{\partial\Omega} \bar{u}_1 \partial_\tau u_1 d \sigma = -\frac{1}{2}\int_{\partial\Omega}\kappa \abs{u}^2 d\sigma
    \end{align*}
    where we used the Frenet-Serret formula above and the fact that at \(\partial\Omega\) we have \(\abs{u_1}^2=\abs{u_2}^2\).
\end{proof}

\begin{proposition}\label{dirac_not_polar}
    Let \(u \in H^2(\Omega)\) a solution of \eqref{dirac} and \(u \in D(\hat{H})\). Then \(u\) cannot be written using separable solutions.
\end{proposition}
\begin{proof}
    We start by showing that \(\abs*{\lambda}>m\) for any eigenvalue \(\lambda\) if \(\kappa = 0\) a.e. Assuming that there exists an eigenvalue \(\lambda\) associated with an eigenfunction \(u\) such that \(\abs{\lambda} \leq m\), by using Lemma \ref*{lemma_sep_norm} we get that 
    \[
    \norm*{\nabla u }_{L^2(\Omega)}^2 + m \norm*{\gamma u}_{L^2(\partial\Omega)}^2 \leq 0 \implies \norm*{\nabla u }_{L^2(\Omega)} = 0 \land m \norm*{\gamma u}_{L^2(\partial\Omega)} = 0
    \]
    and \(u\) must be a constant, which does not satisfy the boundary conditions.

    Since \(u \in H^2(\Omega)\), using \eqref{dirac}, we can express \(u_2\) as
    \[
    u_2 = \frac{-i (\partial_1 + i\partial_2)u_1}{\lambda + m}    
    \]
    allowing us to rewrite Dirac equation \eqref{dirac} using the Helmholtz equation with Cauchy–Riemann oblique boundary conditions:
    \begin{equation}\label{helm_system}
        \begin{cases}
            &-\Delta u_1 = (\lambda^2 - m^2)u_1, \; \text{ in } \Omega\\
            & i (\partial_1 + i\partial_2)u_1 + (\lambda + m)i(n_1 + i n_2)u_1 = 0, \; \text{ on } \Omega.
        \end{cases}      
    \end{equation}
    The rest of the proof will have in consideration two domain types: triangular (on a wedge) and rectangular.
    \begin{enumerate}
    %     \item \(\Omega = \mathbb{D}\):
        
    %     In order to prove the lack of separable solutions in a disk, we convert the system \eqref{helm_system} to polar coordinates, where we use the fact that \(n =\begin{pmatrix}
    %         \cos \theta\\
    %         \sin \theta
    %     \end{pmatrix}\):    
    % \begin{equation}\label{helm_polar_disk}
    %     \begin{cases}
    %         &\Big(\partial_r^2 + \frac{1}{r}\partial_r +\frac{1}{r^2}\partial_\theta^2 \Big)u_1 = (\lambda^2 - m^2)u_1, \; \text{ in } \Omega\\
    %         & i (\cos \theta\partial_r -\frac{1}{r}\sin \theta \partial_\theta + i(\sin \theta\partial_r +\frac{1}{r}\cos \theta \partial_\theta))u_1 + (\lambda + m)i(\cos \theta + i \sin \theta)u_1 = 0, \; \text{ on } \partial\Omega
    %     \end{cases}.      
    % \end{equation}
    % Assuming that there exists a separable solution \(u_1(r, \theta) = R(r)T(\theta)\) of \eqref{helm_polar_disk}, one finds the following equation:
    % \[
    %     \frac{e^{i \theta}(i R(r)T'(\theta) + rT(\theta)((m+\lambda)R(r)+R'(r)))}{r}=0
    % \]
    % which can be rewritten as
    % \[
    % \frac{T'(\theta)}{T(\theta)}=-\frac{r(m R(r)+ \lambda R(r) + R'(r))}{i R(r)}= -k^2    
    % \]
    % for some \(k \in \mathbb{R}\setminus\{0\}\) (otherwise \(T(\theta)=0 \implies u_1(r,\theta) = 0\)). Solving the equations above one finds the family of solutions which satisfies the boundary condition
    % \[
    % u_1(r,\theta) = A e^{-\frac{\theta}{k^2}}e^{-r(m+\lambda)}r^{\frac{i}{k^2}}, \; A \in \mathbb{R}\setminus\{0\}.
    % \]
    % Substituting the family of solutions above in the polar Helmholtz equation we find that
    % \[
    %     \frac{A r^{-1+\frac{i}{k^2}} (\lambda +m) \left(k^2 (2 \lambda  r-1)-2 i\right) e^{-\frac{\theta }{k^2}-r (\lambda +m)}}{k}=0  \implies \lambda = -m
    % \]
    % a contradiction.

    \item Consider \(\Omega\) to be a wedge domain with angle \(\theta\) (see Figure \ref*{wedge}):
    
    \begin{figure}[H]
    \centering
    \begin{tikzpicture}
        % Coordinates of the triangle vertices
        \coordinate[label=left:O] (O) at (0,0);
        \coordinate[label=right:A] (A) at (3,0);
        \coordinate[label=above:B] (B) at (1.5,2.5);
        
        % Drawing the triangle
        \draw (O) -- (A);
        \draw (O) -- (B);
        % Labeling the angle
        \draw (0.6,0) arc (0:60:0.6);
        \node at (0.8,0.3) {$\theta$};
    \end{tikzpicture}
    \caption{A wedge domain with an interior angle \(\theta\).}\label{wedge}
    \end{figure}
    In this case, since the outward unit normal on \(\overline{OA}\) is \(n =\begin{pmatrix}
        0\\
        -1
    \end{pmatrix}\) and on \(\overline{OB}\) is \(n =\begin{pmatrix}
        -\sin \theta\\
        \cos \theta
    \end{pmatrix}\), using polar coordinates system \eqref{helm_system} transforms into
    \begin{equation}\label{helm_polar_wedge}
        \begin{cases}
            &\Big(\partial_r^2 + \frac{1}{r}\partial_r +\frac{1}{r^2}\partial_\theta^2 \Big)u_1 = (\lambda^2 - m^2)u_1, \; \text{ in } \Omega\\
            & i (\cos \theta\partial_r -\frac{1}{r}\sin \theta \partial_\theta + i(\sin \theta\partial_r +\frac{1}{r}\cos \theta \partial_\theta))u_1 + (\lambda + m)u_1 = 0, \; \text{ on } \overline{OA}\\
            & i (\cos \theta\partial_r -\frac{1}{r}\sin \theta \partial_\theta + i(\sin \theta\partial_r +\frac{1}{r}\cos \theta \partial_\theta))u_1 + (\lambda + m)i(-\sin \theta + i \cos \theta)u_1 = 0, \; \text{ on } \overline{OB}
        \end{cases}.      
    \end{equation}
    As such, assuming that exists a solution \(u_1(r, \theta)=\phi(r)T(\theta)\) of the system \eqref{helm_polar_wedge}, from the boundary condition of \(\overline{OB}\) one finds the equation
    \[
        \frac{e^{i \theta } \left(\phi (r) T'(\theta )+r T(\theta ) \left((\lambda +m) \phi (r)-i \phi '(r)\right)\right)}{r}=0
    \]
    which can be rewritten as
    \[
    \frac{T(\theta )}{T'(\theta )} = -\frac{\phi (r)}{r \left(m \phi (r)+\lambda  \phi (r)-i \phi '(r)\right)} = -k^2  
    \]
    for some \(k \in \mathbb{R}\). Solving the equations above we find that
    \[
    u_1(r,\theta) = A e^{-\frac{\theta }{k^2}} r^{\frac{i}{k^2}} e^{-i r (\lambda +m)}, \; A \in \mathbb{R}\setminus{\{0\}}.
    \]
    Substituting in the boundary condition for \(\overline{OA}\) we obtain
    \[
        A \left(1+e^{i \theta }\right) r^{\frac{i}{k^2}} (\lambda +m) e^{-\frac{\theta }{k^2}-i r (\lambda +m)}=0    
    \] where we conclude that \(\lambda=-m\) (since if \(\theta=\pi\) we would have a degenerate wedge), a contradiction.

    \item For rectangular domains, we point the proof in \cite{briet2022spectral}.
    \end{enumerate}     
\end{proof}

\begin{remark}
    A careful reader will note that two important details are being overlooked: triangular domains or quadrilaterals do not have the required smoothness to obtain the formula \eqref{sep_norm} (and signed curvature is not defined everywhere, only on each edge where \(\kappa=0\)), neither \(u\) has enough regularity to be integrated by parts while expanding \eqref{sep_norm_4}. We point to \cite{vu2023spectral}, where such details can be found for triangles, but are analogous for quadrilaterals.
\end{remark}

We now present some open conjectures that we try numerically address in this work:

\begin{conjecture}[A Faber-Krahn type inequality]
    Let \(m \geq 0\) and \(\Omega \subset \mathbb{R}^2\) an open and Lipschitz domain. Then,
    \[
    \lambda_1(\Omega) \geq \lambda_1(\Omega^\ast)
    \]
    where \(\Omega^\ast\) is the disk of the same area or perimeter as \(\Omega\).
\end{conjecture}
Conjecture above is regarded as a hot open problem in spectral geometry \cite{krejcirik_larson_lotoreichik_2019}. In \cite{benguria2017spectral} a geometric lower bound for the first (non-negative) eigenvalue was found, while in \cite{lotoreichik2019sharp} a sharp upper bound (a reverse Faber-Krahn type inequality, like in Theorem \ref*{reverse_faber-krahn}) was proved to hold for convex domains with \(C^3\) boundary. However, due to the difficulty of the problem, simpler versions with domain restrictions to triangles and rectangles are being studied. For example, in \cite{briet2022spectral} a study for rectangles was conducted, where the conjectures below were proved under some extra hypothesis:
\begin{conjecture}[Shape optimization in rectangles]
    Given \(m \geq 0\), let \(\lambda_1(a, b) = \lambda_1(\Omega_{a, b})\) denote the first eigenvalue of the Dirac Operator with infinite-mass boundary conditions in a rectangle with sides \(a\) and \(b\). Then,
    \begin{enumerate}
        \item \textit{Area constraint: } \(\lambda_1(a, \frac{1}{a}) \geq \lambda_1(1, 1), \; \forall a>0 \);
        \item \textit{Perimeter constraint: } \(\lambda_1(a, 2-a) \geq \lambda_1(1, 1), \; \forall a\in (0, 2)\).
    \end{enumerate}
\end{conjecture}
In the same vain, in \cite{vu2023spectral} very similar results were proven for triangles:
\begin{conjecture}[Shape optimization in triangles]
    Consider the triangle \(\Omega_{a, b}\) defined by the points \(O=(0, 0), A=(a, 0), B=(0, b)\) for \(a, b>0\). Then, given any \(m \geq 0\),
    \begin{enumerate}
        \item \textit{Area constraint: } \(\lambda_1(a, b) \geq \lambda(k, k),\; \forall a, b, k >0\) such that \(ab=k^2\);
        \item \textit{Perimeter constraint: } \(\lambda_1(a, b) \geq \lambda(k, k),\; \forall a \in (0, (2+\sqrt(2)k))\) and \(\forall b, k > 0\) such that \(a+b+\sqrt{a^2+b^2}=(2+\sqrt{2})k\).
    \end{enumerate}
\end{conjecture}

\section{A domain decomposition problem}\label{domain_decomp_problem}

We now consider the polygonal domain \(\Omega \subset \mathbb{R}^2\) which we divide into two non-overlapping regions \(\Omega_1\) and \(\Omega_2\) such that \(\overline{\Omega} = \overline{\Omega_1} \cup \overline{\Omega_2}\). We denote their common boundary by \(\gamma = \partial\Omega_1 \cap \partial\Omega_2\) and denote by \(\Gamma_i = \partial\Omega_1\setminus{\gamma}\) the boundary of each domain \(\Omega_1\) minus the common boundary. The problem we address this section is to find functions \(u_1, u_2\) such that
\begin{align}\label{decomp_prob}
    \begin{split}
    - \nabla k_i \nabla u_i &= f_i, \; \text{in }\Omega_i\\
    u_1 - u_2 &= 0, \; \text{on }\gamma\\
    k_1 \frac{\partial u_1}{\partial n_1} + k_2 \frac{\partial u_2}{\partial n_2} &= 0, \; \text{on }\gamma\\
    u_i &= 0, \; \text{on }\Gamma_i
    \end{split}
\end{align}
where \(k_1 \geq k_2 > 0\) are constants, \(f_i \in L^2(\Omega_i)\) is a source function on each domain and \(n_i\) is the (normalized) outward normal to each domain subdomain \(\Omega_i, i=1, 2\). Finally, we will write \(n=n_1=-n_2\) when we are restricted to the interface.

In what follows we mainly used the reference \cite{quarteroni1999domain}. Equations \eqref{decomp_prob} can be used to study a system of two bodies with different material parameters (contact resistance or thermal conductivity) connected by an interface \(\gamma\). If we set
\[
f = \begin{cases}
    \frac{f_1}{k_1},\; \Omega_1\\
    \frac{f_2}{k_2},\; \Omega_2
\end{cases},   
\]
then the problem above can be seen as a natural reformulation of the Poisson equation
\begin{align}\label{decomp_poisson}
    \begin{split}
        -\Delta u = f, \; \text{in }\Omega \\
        u = 0, \; \text{on } \partial\Omega
    \end{split}
\end{align}
where \(f\) is (possibly) discontinuous on the interface \(\gamma\). In order to keep the equivalence between both problems, we enforce some transmission conditions in Equations \eqref{decomp_prob} using the continuity of the solutions and the continuity of their normal derivative on \(\gamma\). To establish the equivalence between both problems we write the variational weak form associated with them. For \eqref{decomp_poisson} it's an easy process: we multiply the equation in \(\Omega\) by a test function \(v \in C^\infty_0(\Omega)\) and using Green's Identity we find that
\[
a(u,v)=\int_\Omega \nabla u \cdot \nabla v = \int_\Omega f v
\]
where \(a\) is the associated bilinear form. As such, enlarging our functional space to the Hilbert Space \(V^0=H^1_0(\Omega)\), our problem can be rewritten as
\begin{equation}\label{weak_poisson}
    \text{find } u \in V^0: a(u,v) = (f, v), \; \forall v \in V^0   
\end{equation}
which has a unique solution in \(V^0\) by virtue of Lax-Milgram lemma. In fact, by regularity results (see Section 6.3.1 of \cite{evans2022partial}), we're looking for \(u \in V^0 \cap H^2_{\text{loc}}(\Omega'), \; \forall \Omega' \Subset \Omega\)\footnote{We say that \(A \Subset B\) when \(\overline{A}\) is compact and \(\overline{A} \subset B\).}. 

For \eqref{decomp_prob} the process is not so direct. For the first equation, for the subdomain \(\Omega_1\), we multiply it with a test function in \(v_1 \in C^\infty_0(\Omega_1)\) and integrate by parts where we get 
\[
a(u_1,v_1) = \int_{\Omega_1} \nabla u_1 \cdot \nabla v_1 = \Big(\frac{f_1}{k_1}, v_1\Big)    
\]
and analogously, for the subdomain \(\Omega_2\), considering \(v_2 \in C^\infty_0(\Omega_2)\) we find
\[
a(u_2,v_2) = \int_{\Omega_2} \nabla u_2 \cdot \nabla v_2 = \Big(\frac{f_2}{k_2}, v_2\Big).        
\]
To add the interface condition on the normal derivative we notice that if we take \(v \in C^\infty_0(\Omega)\), we can define \(v_1 = v_{\Omega_1}\) and \(v_2 = v_{\Omega_2}\), where \(v_i \in C^\infty(\Omega_i)\) and \(v_i(x)=0, \; \forall x \in \Gamma_i\) for \(i=1, 2\). This allows us to write that
\begin{align*}
    -\int_{\Omega_1} k_1 \Delta u_1 v_1 -\int_{\Omega_2} k_2 \Delta u_2 v_2 &= \int_{\Omega_1} k_1\nabla u_1 \cdot \nabla v_1 + \int_{\Omega_2} k_2\nabla u_2 \cdot \nabla v_2\\
    &- k_1 \int_\gamma \frac{\partial u_1}{\partial n_1}v_1 - k_2 \int_\gamma \frac{\partial u_2}{\partial n_2}v_2
\end{align*}
We observe that if \(v_{1_|\gamma} = v_{2_|\gamma} = \eta\), then using the condition on the normal derivative we would find that 
\[
\int_{\Omega_1} k_1\nabla u_1 \cdot \nabla v_1 + \int_{\Omega_2} k_2\nabla u_2 \cdot \nabla v_2 = (f_1, v_1) + (f_2, v_2).
\]
As such, we consider the continuous extension operator \(P_i\) from the interface to each domain \(\Omega_i\) such that \((P_i \eta)_{|\gamma} = \eta\). In that case, given a function \(\mu\) defined in \(\gamma\)\footnote{A description of such function will be given below, when we formalize the weak form of the problem. For now assume that such extension has the regularity that we need.}, the identity above holds if we rewrite it in the form
\[
\int_{\Omega_1} k_1\nabla u_1 \cdot \nabla P_1 \mu + \int_{\Omega_2} k_2\nabla u_2 \cdot \nabla P_2 \mu = (f_1, P_1 \mu) + (f_2, P_2 \mu).  
\]
Finally, for the continuity on the interface we just enforce that \(u_1 = u_2\) on \(\gamma\). The process above allow us to state the weak form of problem \eqref{decomp_prob} in the result below.
\begin{proposition}
    Consider the set of equations \eqref{decomp_prob} and the bilinear form \(a_i = (w_i, v_i) = (\nabla w_i, \nabla v_i)\). Let
    \begin{align*}
        &V_i = \{v_i \in H^1(\Omega_i): v_{i_{|\partial \Omega \cap \partial {\Omega_i}}=0\}};\\
        &V_i^0 = H^1_0(\Omega_i)\\
        &\Lambda = \{\eta \in H^\frac{1}{2}(\gamma): \eta = v_{|\gamma} \text{ for some } v \in V^0\} 
    \end{align*}
    where \(V^0 = H^1_0(\Omega)\) as above.
    Then the weak formulation of \eqref{decomp_prob} reads as
    \begin{equation}\label{weak_decomp}
        \text{find } u_1\in V_1, u_2 \in V_2 \text{ such that }
        \begin{cases}
            a_1(u_1, v_1) = (\frac{f_1}{k_1}, v_1), \; \forall v_1 \in V_1^0\\
            a_2(u_2, v_2) = (\frac{f_2}{k_2}, v_1), \; \forall v_2 \in V_2^0\\
            u_1 = u_2, \; \text{ on } \gamma\\
            a_1(k_1 u_1, P_1 \mu) + a_2(k_2 u_2, P_2 \mu) = (f_1, P_1 \mu) + (f_2, P_2 \mu), \; \forall \mu \in \Lambda
        \end{cases}
    \end{equation}
    where the operator \(P_i: \Lambda \rightarrow V_i\) is continuous for \(i=1, 2\).
\end{proposition}

\begin{remark}
    The existence of the (continuous) extension operators \(P_1\) and \(P_2\) is not obvious. See \cite{adams2003sobolev} or \cite{lions2012non} for the existence of such operator. 
\end{remark}

We are now ready to prove the equivalence between both problems:
\begin{theorem}\label{equivalence_transmission}
    Problem \eqref{weak_poisson} is equivalent to \eqref{weak_decomp}.
\end{theorem}
\begin{proof}
    \((\implies):\)

    Let \(u \in V^0\) be a solution of problem \eqref{weak_poisson}. We start by defining \(u_1 = u_{\Omega_1}\) and \(u_2 = u_{\Omega_2}\). It's clear that \(u_1\) and \(u_2\) satisfy equations 1 and 2 of \eqref{weak_decomp}. 
    
    For equation 3, we use the fact that \(u \in H^1(\Omega)\) and therefore \(u \in H^2_{\text{loc}}(\Omega)\). Given \(\Omega'\) such that \(\Omega' \Subset \Omega\) and \(\gamma \subset \Omega'\), we have that \(u \in H^2(\Omega')\) and \(u \in C^{0,\lambda}(\overline{\Omega'})\) (\(u\) is in the H\"{o}lder Space of exponent \(\lambda\); see Theorem 4.12 of \cite{adams2003sobolev} for more details.) As such, \(u\) is continuous on the interface and \(u_1=u_2\) on \(\gamma\).

    Finally, given \(\mu \in \Lambda\), we can define the function
    \[
        P \mu =
    \begin{cases}
        P_1 \mu\\
        P_2 \mu
    \end{cases}
    \]
    which satisfies \(P \mu \in V^0\) and the equality 4 in \eqref{weak_decomp}.

    \vspace*{0.5cm}
    \((\impliedby):\)

    Let \(u_1 \in V_1^0, u_2 \in V_2^0\) be the two solutions of problem \eqref{weak_poisson}. We now set
    \[
    u=\begin{cases}
        u_1, \text{ in } \Omega_1\\
        u_2, \text{ in } \Omega_2
    \end{cases}.
    \]
    In this case, we again notice that for \(i=1, 2\) we have \(u_i \in H^2_{\text{loc}}\) which implies that \(u_1\) and \(u_2\) is H\"{o}lder continuous and therefore \(u\) is also H\"{o}lder continuous since \(u_1 = u_2\) on the interface, by assumption. Therefore, we also have that \(u \in V^0\). 
    
    Defining \(P \mu\) like above, we take \(\mu \in \Lambda\) for some \(v \in V\) such that \(\mu = v_{|\gamma}\). As such, we have that the difference \((v_{|\Omega_i} - P_i \mu) \in V^0_i\) for each \(i=1, 2\) and
    \begin{align*}
        a(k u, v) &= \Big[a_1(k_1 u_1, v_{|\Omega_1} - P_1 \mu) + a_1(k_1 u_1, P_1\mu)\Big] + \Big[a_2(k_2 u_2, v_{|\Omega_2} - P_2 \mu) + a_2(k_2 u_2, P_2\mu)\Big]\\
        &=\Big[(f_1, v_{|\Omega_1} - P_1 \mu) + (f_1, P_1 \mu) \Big] + \Big[(f_2, v_{|\Omega_2} - P_2 \mu) + (f_2, P_2 \mu) \Big]\\
        &=(\Tilde{f}, v), \implies a(u, v) = (f, v)
    \end{align*}
    where we take \(\Tilde{f} = \begin{cases}
        f_1, \text{ in } \Omega_1\\
        f_2, \text{ in } \Omega_2
    \end{cases}\)
    as an auxiliary function and used the assumptions 1, 2 and 4 of equations \eqref{weak_decomp}.
\end{proof}

\begin{remark}
    The above result is important because, as we will see, the Method of Fundamental Solutions only addresses the solution of each subdomain \(\Omega_i\) independently (for which we have density and convergence results for functions in \(H^1\)) while enforcing the interface conditions. By the result above we're, in fact, in the conditions of our numerical method since each function belongs to a closed subspace of \(H^1(\Omega_i)\) for \(i=1, 2\).
\end{remark}

% \textit{Posteriori estimate}:

% We now look to prove that the error obtained in the numerical approximation using the MFS only depends on the boundary and interface error. With that in mind, we start by introducing some auxiliary results and concepts that we need. See \cite{salsa2016partial}, \cite{evans2022partial} or \cite{huguinho}.
% \begin{lemma}\label{rep_c2}
%     Let \(\Omega \subset \mathbb{R}^d\) be a smooth, bounded domain and \(u \in C^2(\overline{\Omega})\). Then, for every \(x \in \Omega\),
%     \[
%     u(x) = -\int_\Omega \Phi(x-y)\Delta u(y) dy + \int_{\partial \Omega} \Phi(x-y)\frac{\partial u}{\partial n}(y) - u(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)
%     \]
% \end{lemma}
% \begin{proof}
%     See Theorem 3.11 in \cite{sauvigny2012partial}.\footnote{The proof given in the reference assumes weaker assumptions than the ones listed here. This lemma can be proven just assuming that \(u \in C^2(\Omega)\cap C^1(\overline{\Omega})\), \(\Omega\) is a \textit{normal} domain (like rectangles), and we are in the conditions of the Divergence Theorem.}
% \end{proof}
% \begin{lemma}\label{phi}
%     Consider \(u \in C^2(\overline{\Omega})\) in the same conditions as in Lemma \ref{rep_c2}. Assume that there exists \(\varphi(x, \cdot) \in C^2(\overline{\Omega})\) such that
%     \[
%     \begin{cases}
%         \Delta_y \varphi = 0, \; y \in \Omega\\
%         \varphi(x, y) = \Phi(x-y), \; y \in \partial \Omega 
%     \end{cases}    
%     \]
%     for every \(x \in \Omega\). Then 
%     \[
%     \int_{\partial\Omega} \Phi(x-y)\frac{\partial u}{\partial n}(y) d\sigma(y) = \int_\Omega \varphi(x, y)\Delta u(y) dy  + \int_{\partial\Omega} \frac{\partial \varphi}{\partial n_y}(x,y) u(y) d\sigma(y).
%     \]
% \end{lemma}
% \begin{proof}
%     Using Green's third identity we find that
%     \begin{align*}
%     \int_\Omega \underbrace{\Delta_y \varphi(x, y) u(y)}_{=0} - \varphi(x, y)\Delta u(y)dy &= \int_{\partial\Omega} \frac{\partial \varphi}{\partial n_y}(x,y) u(y) - \varphi(x, y)\frac{\partial u}{\partial n}(y)  d\sigma(y)\\
%     &\int_{\partial\Omega} \frac{\partial \Phi}{\partial n_y}(x-y) u(y) - \Phi(x-y)\frac{\partial u}{\partial n}(y)  d\sigma(y)
% \end{align*}
% as we wanted.
% \end{proof}
% \begin{definition}[Green's function]
%     With the same assumptions as in Lemma \ref{phi}, we define the Green's function of \(\Omega\) as
%     \[
%     G(x, y) = \Phi(x-y) - \phi(x, y), \; \forall x \in \Omega, y \in \overline{\Omega}, x \neq y   
%     \]
%     which satisfies 
%     \[
%         \begin{cases}
%             \Delta_y G(x,y) = \delta_x, \; y \in \Omega\\
%             G(x, y) = 0, \; y \in \partial \Omega 
%         \end{cases}.
%     \]
%     We say that the fundamental solution \(\Phi(x-y)\) is the singular part of \(G\) and \(\varphi(x,y)\) is the regular part.
% \end{definition}
% \begin{remark}\label{remarck_green}
%     The existence of the Green function for a general domain \(\Omega\) depends on the solvability of the problem 
%     \[
%         \begin{cases}
%             \Delta_y \varphi = 0, \; y \in \Omega\\
%             \varphi(x, y) = \Phi(x-y), \; y \in \partial \Omega 
%         \end{cases}       
%     \]
%     which can be asserted for a Lipschitz domain. See Theorem 3.8 in \cite{salsa2016partial}\footnote{Observe that \(\forall y \in \partial \Omega, \; \phi(x, y) = \Phi(x-y)\) is never singular since \(x \in \Omega\)}.

%     Assuming that the domain admits a Green function, then we can improve on Lemma \ref{rep_c2}. Given \(u \in C^2(\Omega)\cap C^1(\overline{\Omega})\) we can represent it as
%     \[
%         u(x) =  \int_{\Omega} G(x, y)\Delta u(y) \sigma(y) -\int_{\partial\Omega} \frac{\partial G}{\partial n_y}(x, y) u(y) \sigma(y).
%     \]
%     In particular, if \(u\) satisfies the Poisson equation with Dirichlet boundary conditions, then
%     \[
%         u(x) =  \int_{\Omega} G(x, y) f(y) \sigma(y) -\int_{\partial\Omega} \frac{\partial G}{\partial n_y}(x, y) g(y) \sigma(y).
%     \]

% \end{remark}

% \begin{lemma}\label{super_lemma}
%     Let \(\Omega\) be a smooth, open and bounded set. Then \(\forall x \in \Omega, y \in \partial \Omega\)
%     \begin{align*}
%         &\frac{\partial G}{\partial n_y}(x, y) < 0\\ 
%         &\frac{\partial \Phi}{\partial n_y}(x-y) < 0.
%     \end{align*}
% \end{lemma}
% \begin{proof}
%     Let \(u \in C^2(\Omega)\cap C^1(\overline{\Omega})\) be a solution of 
%     \[
%     \begin{cases}
%         \Delta u(x) = 0, x \in \Omega\\
%         u(x) = g(x), x \in \partial \Omega
%     \end{cases}
%     \]
%     where \(g\) is a nonnegative and arbitrary continuous function (it is known that such \(u\) exists). By the maximum principle (applied to \(-u\)) we know that \(u(x) > 0\). Since \(u\) can be represented by
%     \[
%     u(x) = -\int_{\partial\Omega} \frac{\partial G}{\partial n_y}(x, y)g(y) \sigma(y)
%     \]
%     we find that the integral above is negative, which implies that \(\frac{\partial G}{\partial n_y}(x, y)\) must also be negative because \(g\) is arbitrary.
%     To prove that
%     \[
%         \frac{\partial \Phi}{\partial n_y}(x-y) < 0    
%     \]
%     it suffices to notice that \(\Phi\) is radially symmetric and \(\Phi(x) = \Phi(r)\), with \(r \in \mathbb{R}_0^+\) and \(\Phi'(r) = -\frac{1}{2 \pi r} < 0\).
% \end{proof}
% Let \(u = (u_1, u_2)\) be the solution of \eqref{decomp_prob} and \(\Tilde{u} = (\Tilde{u}_1, \Tilde{u}_2)\) the numerical approximation given by the method of fundamental solutions. Then, we have that
% \begin{align}
%     \begin{split}
%         \begin{cases}
%             -\Delta u_i &= 0, \; \text{in }\Omega_i\\
%             u_1 &= u_2, \; \text{on }\gamma\\
%             \frac{\partial u_1}{\partial n} &= \frac{\partial u_2}{\partial n}, \; \text{on }\gamma\\
%             u_i &= 0, \; \text{on }\Gamma_i
%         \end{cases}
%     \end{split}
%     \quad
%     \begin{split}
%         \begin{cases}
%             -\Delta \Tilde{u}_i &= 0, \; \text{in }\Omega_i\\
%             \Tilde{u}_1 &= \Tilde{u}_2 + \Tilde{g}_1, \; \text{on }\gamma\\
%             \frac{\partial \Tilde{u}_1}{\partial n} &= \frac{\partial \Tilde{u}_2}{\partial n} + \Tilde{g}_2, \; \text{on }\gamma\\
%             \Tilde{u}_i &=  \Tilde{h}_i, \; \text{on }\Gamma_i
%         \end{cases}
%     \end{split}
% \end{align}
% where \(\Tilde{g}_i \in L^\infty(\gamma), \Tilde{h}_1 \in L^\infty(\Gamma_i)\) are the numerical approximation at \(\gamma\) and \(\Gamma_i\) (we recall that our numerical approximation satisfies \eqref{decomp_poisson} in the interior of each \(\Omega_i\) by construction).

% We now state and prove the desired \textit{Posteriori} estimate.
% \begin{theorem}
%     Consider \(u\) and \(\Tilde{u}\) defined as above and assume that \(\Omega\) is a smooth and bounded domain of \(\mathbb{R}^2\). Then, there exists a constant \(C > 0\) that only depends on the domains \(\Omega_1\) and \(\Omega_2\) such that
%     \[
%     \norm*{u-\Tilde{u}} \leq C(\norm*{\Tilde{g}_1} + \norm*{\Tilde{g}_2} + \norm*{\Tilde{h}_1} + \norm*{\Tilde{h}_2})
%     \]
% \end{theorem}
% \begin{proof}
%     Using the representation Lemma \ref{rep_c2} we find that
%     \begin{align*}
%         &u_1(x) = \int_{\Gamma_1} \Phi(x-y)\frac{\partial u_1}{\partial n_1}(y) d\sigma(y)+\int_{\gamma} \Phi(x-y)\frac{\partial u_1}{\partial n}(y) - u_1(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\\
%         &u_2(x) = \int_{\Gamma_2} \Phi(x-y)\frac{\partial u_2}{\partial n_2}(y) d\sigma(y)-\Big(\int_{\gamma} \Phi(x-y)\frac{\partial u_2}{\partial n}(y) - u_2(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\Big)
%     \end{align*}
%     where we used the fact that \(u_1\) and \(u_2\) vanish on the boundaries \(\Gamma_1\) and \(\Gamma_2\), respectively, and \(\frac{\partial u_2}{\partial n_2} = -\frac{\partial u_2}{\partial n}\) since \(n = n_1 = n_2\) on the interface.
%     Analogously, we can represent \(\Tilde{u}_1\) and \(\Tilde{u}_2\) in the integral form
%     \begin{align*}
%         &\Tilde{u}_1(x) =  \int_{\Gamma_1} \Phi(x-y)\frac{\partial \Tilde{u}_1}{\partial n_1}(y) - \Tilde{h}_1(y) \frac{\partial \Phi}{\partial n_1}(x-y) d\sigma(y) + \int_{\gamma} \Phi(x-y)\frac{\partial \Tilde{u}_1}{\partial n}(y) - \Tilde{u}_1(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\\
%         &\Tilde{u}_2(x) = \int_{\Gamma_2} \Phi(x-y)\frac{\partial \Tilde{u}_2}{\partial n_2}(y) - \Tilde{h}_2(y) \frac{\partial \Phi}{\partial n_2}(x-y) d\sigma(y) -\Big(\int_{\gamma} \Phi(x-y)\frac{\partial \Tilde{u}_2}{\partial n}(y) - \Tilde{u}_2(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\Big)
%     \end{align*}

%     \begin{align*}
%         (u_1-\Tilde{u}_1)(x) &= \int_{\Gamma_1} \Phi(x-y)\Big(\frac{\partial u_1}{\partial n_1}(y)-\frac{\partial \Tilde{u}_1}{\partial n_1}(y)\Big)d\sigma(y) + \int_{\Gamma_1}\Tilde{h}_1(y) \frac{\partial \Phi}{\partial n_1}(x-y) d\sigma(y)\\
%         &+ \int_{\gamma} \Phi(x-y)\Big(\frac{\partial u_1}{\partial n}(y)-\frac{\partial \Tilde{u}_1}{\partial n}(y)\Big) - \Big(u_1(y)-\Tilde{u}_1(y)\Big) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)
%     \end{align*}
%     \begin{align*}
%         (u_2-\Tilde{u}_2)(x) &= \int_{\Gamma_2} \Phi(x-y)\Big(\frac{\partial u_2}{\partial n_2}(y)-\frac{\partial \Tilde{u}_2}{\partial n_2}(y)\Big)d\sigma(y) + \int_{\Gamma_2}\Tilde{h}_2(y) \frac{\partial \Phi}{\partial n_2}(x-y) d\sigma(y)\\
%         &+\int_{\gamma} -\Phi(x-y)\Big(\frac{\partial u_2}{\partial n}(y)-\frac{\partial \Tilde{u}_2}{\partial n}(y)\Big) + \Big(u_2(y)-\Tilde{u}_2(y)\Big) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)
%     \end{align*}
%     Since,
%     \[
%         (u-\Tilde{u})(x) = \chi_{\Omega_1}(u_1-\Tilde{u}_1)(x) + \chi_{\Omega_2}(u_2-\Tilde{u}_2)(x) 
%     \]
%     and writing
%     \[
%     \Tilde{h}(x) = \begin{cases}
%         \Tilde{h}_1(x), \Gamma_1\\
%         \Tilde{h}_2(x), \Gamma_2
%     \end{cases}  
%     \]
%     \begin{align*}
%         (u-\Tilde{u})(x) &= \int_{\partial\Omega} \Phi(x-y)\Big(\frac{\partial u}{\partial n}(y)-\frac{\partial \Tilde{u}}{\partial n}(y)\Big)d\sigma(y) + \int_{\partial\Omega}\Tilde{h}(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\\
%         &-\int_{\gamma} \Phi(x-y)\Tilde{g}_2 - \Tilde{g}_1\frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)
%     \end{align*}


    % where we used the fact that \(\Tilde{u}_i = \Tilde{h}_i\) on \(\Gamma_i\).  To deal with the boundary term \(\int_{\Gamma_i} \Phi(x-y)\frac{\partial \Tilde{u}_i}{\partial n_i}(y) d\sigma(y)\), we make use of Lemma \ref{phi} which allow us to rewrite
    % \begin{align*}
    %     &\Tilde{u}_1(x) = -\int_{\Gamma_1} \frac{\partial G_1}{\partial n_1}(x,y)\Tilde{h}_1(y) d\sigma(y) + \int_{\gamma} \Phi(x-y)\frac{\partial \Tilde{u}_1}{\partial n}(y) - \Tilde{u}_1(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\\
    %     &\Tilde{u}_2(x) = -\int_{\Gamma_2} \frac{\partial G_2}{\partial n_2}(x,y)\Tilde{h}_2(y) d\sigma(y) -\Big(\int_{\gamma} \Phi(x-y)\frac{\partial \Tilde{u}_2}{\partial n}(y) - \Tilde{u}_2(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\Big)
    % \end{align*}
    % using the Green's function \(G_i\) for each domain \(\Omega_i\).
    % Computing the error function \(u_i - \Tilde{u}_i\) for each domain \(\Omega_i\) holds
    % \begin{equation*}
    %     (u_1-\Tilde{u}_1)(x) = \int_{\gamma} \Phi(x-y)\Big(\frac{\partial u_1}{\partial n}-\frac{\partial \Tilde{u}_1}{\partial n}\Big)(y) - (u_1 - \Tilde{u}_1)(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y) + \int_{\Gamma_1} \frac{\partial G_1}{\partial n_1}(x,y)\Tilde{h}_1(y) d\sigma(y)
    % \end{equation*}
    % \begin{align*}
    %     (u_2-\Tilde{u}_2)(x) =& -\Bigg(\int_{\gamma} \Phi(x-y)\Big(\frac{\partial u_2}{\partial n}-\frac{\partial \Tilde{u}_2}{\partial n}\Big)(y) - (u_2 - \Tilde{u}_1)(y) \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\Bigg)\\
    %     & \qquad + \int_{\Gamma_2} \frac{\partial G_2}{\partial n_2}(x,y)\Tilde{h}_2(y) d\sigma(y)\\
    %     &= -\Bigg(\int_{\gamma} \Phi(x-y)\Big[\Big(\frac{\partial u_1}{\partial n}-\frac{\partial \Tilde{u}_1}{\partial n}\Big)(y) + \Tilde{g}_2(y)\Big] - \Big[(u_1 - \Tilde{u}_1)(y)+\Tilde{g}_1(y)\Big] \frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\Bigg)\\
    %     & \qquad +\int_{\Gamma_2} \frac{\partial G_2}{\partial n_2}(x,y)\Tilde{h}_2(y) d\sigma(y)
    % \end{align*}
    % Summing both expressions we find that
    % \begin{align*}
    %     (u-\Tilde{u})(x) &= (u_1-\Tilde{u}_1)(x) + (u_2-\Tilde{u}_2)(x)\\
    %     & = -\int_{\gamma} \Phi(x-y)\Tilde{g}_2(y) - \Tilde{g}_1(y)\frac{\partial \Phi}{\partial n}(x-y) d\sigma(y)\\
    %     & \quad + \int_{\Gamma_1} \frac{\partial G_1}{\partial n_1}(x,y)\Tilde{h}_1(y) d\sigma(y)\\
    %     & \quad +\int_{\Gamma_2} \frac{\partial G_2}{\partial n_2}(x,y)\Tilde{h}_2(y) d\sigma(y)
    % \end{align*}
    % Applying the absolute value in the identity above in conjunction with the triangle inequality we get
    % \begin{align*}
    % \abs{(u-\Tilde{u})(x)} &\leq \int_{\gamma} \abs{\Phi(x-y)\Tilde{g}_2(y)}d\sigma(y) + \int_{\gamma} \abs{\frac{\partial \Phi}{\partial n}(x-y)\Tilde{g}_1(y)}d\sigma(y)\\
    % & \; + \int_{\Gamma_1} \abs{\frac{\partial G_1}{\partial n_1}(x,y)\Tilde{h}_1(y)} d\sigma(y) + \int_{\Gamma2} \abs{\frac{\partial G2}{\partial n_2}(x,y)\Tilde{h}_2(y)} d\sigma(y)\\
    % & \leq \abs{\int_{\partial \Omega} \abs{\Phi(x-y)}d\sigma(y)} \norm*{\Tilde{g}_2}_{L^\infty(\gamma)} + \abs{\int_{\partial \Omega} \abs{\frac{\partial \Phi}{\partial n}(x-y)}d\sigma(y) \norm*{\Tilde{g}_1}_{L^\infty(\gamma)}}\\
    % & \; + \abs{\int_{\partial \Omega_1} \abs{\frac{\partial G_1}{\partial n_1}(x,y)}d\sigma(y)}\norm*{\Tilde{h}_1}_{L^\infty(\Gamma_1)} + \abs{\int_{\partial \Omega_2} \abs{\frac{\partial G_2}{\partial n_2}(x,y)}d\sigma(y)} \norm*{\Tilde{h}_2}_{L^\infty(\Gamma_2)}
    % \end{align*}
    % where we extended the integral to the boundary of the domain since the integrand is positive.
    % Since \(\Phi \in L^1_{\text{loc}}(\mathbb{R}^2)\) and by Lemma \ref{super_lemma} we find that
    % \begin{align*}
    %     \abs{(u-\Tilde{u})(x)} &\leq C\norm*{\Tilde{g}_2}_{L^\infty(\gamma)} + \abs{\int_{\partial \Omega} \frac{\partial \Phi}{\partial n}(x-y)d\sigma(y)} \norm*{\Tilde{g}_1}_{L^\infty(\gamma)}\\
    %     & \; + \abs{\int_{\partial \Omega_1} \frac{\partial G_1}{\partial n_1}(x,y)d\sigma(y)} \norm*{\Tilde{h}_1}_{L^\infty(\Gamma_1)} + \abs{\int_{\partial \Omega_2} \frac{\partial G_2}{\partial n_2}(x,y)d\sigma(y)} \norm*{\Tilde{h}_2}_{L^\infty(\Gamma_2)}.
    % \end{align*}
    % % Using Divergence Theorem one can find that
    % % \[
    % % \int_\Omega \Delta u(x) dx = \int_\partial_Omega \frac{\partial u}{\partial n}(x) d\sigma(x)
    % % \]
    % From Divergence Theorem and 
    % \[
    %     \int_{\partial \Omega} \frac{\partial \Phi}{\partial n}(x-y)d\sigma(y) = -1
    % \]
    % we can write
    % \begin{align*}
    %     \abs{(u-\Tilde{u})(x)} &\leq C\norm*{\Tilde{g}_2}_{L^\infty(\gamma)} + \norm*{\Tilde{g}_1}_{L^\infty(\gamma)}\\
    %     & \; + \abs{\int_{\Omega_1} \Delta G_1(x,y) dy} \norm*{\Tilde{h}_1}_{L^\infty(\Gamma_1)} + \abs{\int_{\Omega_2} \Delta G_2(x,y) dy} \norm*{\Tilde{h}_2}_{L^\infty(\Gamma_2)}\\
    %     & = C\norm*{\Tilde{g}_2}_{L^\infty(\gamma)} + \norm*{\Tilde{g}_1}_{L^\infty(\gamma)} + \norm*{\Tilde{h}_1}_{L^\infty(\Gamma_1)} + \norm*{\Tilde{h}_2}_{L^\infty(\Gamma_2)}
    % \end{align*}
    % given that \(\Delta G(x,y) = \delta_x\).
    % Finally, choosing \(M = \max\{C, 1\}\) and since the inequality above holds for any \(x \in \Omega\) we conclude that
    % \[
    %     \norm{(u-\Tilde{u})(x)}_{L^\infty(\Omega)} \leq M(\norm*{\Tilde{g}_2}_{L^\infty(\gamma)} + \norm*{\Tilde{g}_1}_{L^\infty(\gamma)} + \norm*{\Tilde{h}_1}_{L^\infty(\Gamma_1)} + \norm*{\Tilde{h}_2}_{L^\infty(\Gamma_2)}).
    % \]
% \end{proof}